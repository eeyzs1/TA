{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28ce91c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d79ebb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace \n",
    "from datetime import datetime, timedelta\n",
    "import akshare as ak\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "# import threading\n",
    "import threading\n",
    "import queue\n",
    "import psutil\n",
    "import time\n",
    "import talib\n",
    "from concurrent.futures  import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "# import kline_daily\n",
    "import requests\n",
    "# import cloudscraper\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9653e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stock_zh_a_hist_tx(\n",
    "        symbol: str = \"sz000001\",\n",
    "        start_date: str = \"19000101\",\n",
    "        end_date: str = \"20500101\",\n",
    "        adjust: str = \"\",\n",
    "        timeout: float = None,\n",
    ") -> pd.DataFrame:\n",
    "    url = \"https://proxy.finance.qq.com/ifzqgtimg/appstock/app/newfqkline/get\"\n",
    "    big_df = pd.DataFrame()\n",
    "    params = {\n",
    "        \"_var\": f\"kline_day{adjust}{int(start_date[:4])}\",\n",
    "        \"param\": f\"{symbol},day,{start_date},{end_date},640,{adjust}\",\n",
    "        \"r\": \"0.8205512681390605\",\n",
    "    }\n",
    "    r = requests.get(url, params=params, timeout=timeout)\n",
    "    data_text = r.text\n",
    "    data_json = ak.utils.demjson.decode(data_text[data_text.find(\"={\") + 1:])[\"data\"][\n",
    "        symbol\n",
    "    ]\n",
    "    if \"day\" in data_json.keys():\n",
    "        temp_df = pd.DataFrame(data_json[\"day\"])\n",
    "    elif \"hfqday\" in data_json.keys():\n",
    "        temp_df = pd.DataFrame(data_json[\"hfqday\"])\n",
    "    else:\n",
    "        temp_df = pd.DataFrame(data_json[\"qfqday\"])\n",
    "    big_df = pd.concat([big_df, temp_df], ignore_index=True)\n",
    "    \n",
    "    big_df = big_df.iloc[:, [0,1,2,3,4,5,7]]\n",
    "    big_df.columns = [\"date\", \"open\", \"close\", \"high\", \"low\", \"volume\",\"turnover_rate\"]\n",
    "    big_df[\"date\"] = pd.to_datetime(big_df[\"date\"], errors=\"coerce\").dt.date\n",
    "    big_df[\"open\"] = pd.to_numeric(big_df[\"open\"], errors=\"coerce\")\n",
    "    big_df[\"close\"] = pd.to_numeric(big_df[\"close\"], errors=\"coerce\")\n",
    "    big_df[\"high\"] = pd.to_numeric(big_df[\"high\"], errors=\"coerce\")\n",
    "    big_df[\"low\"] = pd.to_numeric(big_df[\"low\"], errors=\"coerce\")\n",
    "    big_df[\"volume\"] = pd.to_numeric(big_df[\"volume\"], errors=\"coerce\")\n",
    "    big_df[\"turnover_rate\"] = pd.to_numeric(big_df[\"turnover_rate\"], errors=\"coerce\")\n",
    "    big_df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    big_df.index = pd.to_datetime(big_df[\"date\"])\n",
    "    big_df = big_df[start_date:end_date]\n",
    "    big_df.reset_index(inplace=True, drop=True)\n",
    "    return big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a6dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置 root logger：记录 DEBUG 及以上到 all.log \n",
    "logging.basicConfig( \n",
    "    filename='all.log', \n",
    "    filemode='a',\n",
    "    level=logging.DEBUG,\n",
    "    encoding='utf-8',\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    " \n",
    "# 创建 error logger\n",
    "error_logger = logging.getLogger('error_logger') \n",
    "error_logger.setLevel(logging.ERROR)   # 设置 error_logger 只处理 ERROR 及以上级别 \n",
    " \n",
    "# 创建 error.log  的 handler\n",
    "error_handler = logging.FileHandler('error.log',  encoding='utf-8') \n",
    "error_handler.setLevel(logging.ERROR) \n",
    " \n",
    "# 设置 error 日志格式\n",
    "error_formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "error_handler.setFormatter(error_formatter) \n",
    " \n",
    "# 添加 handler 到 error_logger \n",
    "error_logger.addHandler(error_handler) \n",
    " \n",
    "# 防止日志重复传播到 root logger（避免 error 日志出现在 all.log  中两次）\n",
    "error_logger.propagate  = False\n",
    " \n",
    "# 测试日志\n",
    "logging.debug(' 这是 root logger 的 DEBUG 日志，写入 all.log') \n",
    "logging.info(' 这是 root logger 的 INFO 日志，写入 all.log') \n",
    "logging.critical(' 这是 root logger 的 Critical 日志，写入 all.log') \n",
    "error_logger.error(' 这是一个 ERROR 日志，写入 error.log  和 all.log （除非 propagate=False）')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "135e595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.error(\"dwdw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3b0d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_len = len(df)\n",
    "physical_cpus = psutil.cpu_count(logical=False)\n",
    "logical_cpus = psutil.cpu_count(logical=True)\n",
    "\n",
    "log_phy_ratio = int(logical_cpus/physical_cpus)\n",
    "# phy_cpu_length = int(total_len/physical_cpus)\n",
    "args = SimpleNamespace(\n",
    "    datedelta = 50,\n",
    "    start_epochs = 8\n",
    "    )\n",
    "today = datetime.now()\n",
    "start_day = today - timedelta(days=args.datedelta)\n",
    "test_day = today - timedelta(days=1)\n",
    "\n",
    "# 格式化日期为YYYYMMDD格式\n",
    "# formatted_today = today.strftime('%Y%m%d')\n",
    "# formatted_test_day = test_day.strftime('%Y%m%d')\n",
    "# formatted_start_day = start_day.strftime('%Y%m%d')\n",
    "\n",
    "# 格式化日期为YYYY-MM-DD格式\n",
    "formatted_today = today.strftime('%Y-%m-%d')\n",
    "formatted_test_day = test_day.strftime('%Y-%m-%d')\n",
    "formatted_start_day = start_day.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fcc91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('today_suggestions.txt', 'w', encoding='utf-8') as today_suggestions,open('history_suggestions.txt', 'a', encoding='utf-8') as history_suggestions:\n",
    "    today_suggestions.write(formatted_today + \"!!!!!!!!~~~~~~~~~~~~~~\\n\")\n",
    "    history_suggestions.write(formatted_today + \"!!!!!!!!!!!~~~~~~~~~~~~\\n\")\n",
    "# df = pd.read_csv('data.csv',  dtype={0: str})\n",
    "df = pd.read_csv('mainboard_stocks_with_prefix.csv', dtype={'code': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10e31cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sz000001</td>\n",
       "      <td>平安银行</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sz000002</td>\n",
       "      <td>万  科Ａ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sz000004</td>\n",
       "      <td>*ST国华</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sz000006</td>\n",
       "      <td>深振业Ａ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sz000007</td>\n",
       "      <td>全新好</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code   name\n",
       "0  sz000001   平安银行\n",
       "1  sz000002  万  科Ａ\n",
       "2  sz000004  *ST国华\n",
       "3  sz000006   深振业Ａ\n",
       "4  sz000007    全新好"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_codes = list(set(df['code']))\n",
    "print(len(df) == len(stock_codes))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe2b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_data_getter(stock_codes, formatted_start_day, formatted_today):\n",
    "    res_ls = []\n",
    "    for stock_code in stock_codes:\n",
    "        # time.sleep(0.8) #avoid abandon from remote\n",
    "        try:\n",
    "            stock_zh_a_hist_df = stock_zh_a_hist_tx(symbol=stock_code, start_date=formatted_start_day, end_date=formatted_today)\n",
    "            if stock_zh_a_hist_df.empty:\n",
    "                print(\"wrong code:\",stock_code)\n",
    "            else:\n",
    "                res_ls.append((stock_code, stock_zh_a_hist_df))\n",
    "        except Exception as e:\n",
    "            print(\"exception:\",e)\n",
    "            logging.error(e)\n",
    "    print(\"stock code:\",stock_codes[-1],\"data collection finished:\", time.time())\n",
    "    return res_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcdb32ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock code: sh605499 data collection finished: 1757326028.9484198\n",
      "stock code: sz000506 data collection finished: 1757326031.7953784\n",
      "stock code: sh601702 data collection finished: 1757326033.757046\n",
      "stock code: sh605081 data collection finished: 1757326033.795189\n",
      "stock code: sz002579 data collection finished: 1757326033.9995246\n",
      "stock code: sh605266 data collection finished: 1757326034.1717873\n",
      "stock code: sh603070 data collection finished: 1757326034.191254\n",
      "stock code: sh603060 data collection finished: 1757326034.5333939\n",
      "stock code: sz002615 data collection finished: 1757326034.5920234\n",
      "stock code: sh600118 data collection finished: 1757326034.8382812\n",
      "stock code: sh600279 data collection finished: 1757326034.856416\n",
      "stock code: sz000509 data collection finished: 1757326035.0523624\n",
      "stock code: sh603767 data collection finished: 1757326035.0933843\n",
      "stock code: sh600448 data collection finished: 1757326035.3939307\n",
      "stock code: sz000530 data collection finished: 1757326035.5271244\n",
      "stock code: sz000691 data collection finished: 1757326035.6277986\n",
      "stock code: sh603205 data collection finished: 1757326035.8572826\n",
      "stock code: sz002695 data collection finished: 1757326036.2581253\n",
      "stock code: sz000598 data collection finished: 1757326036.3798857\n",
      "stock code: sh603956 data collection finished: 1757326036.3958461\n",
      "stock code: sh603031 data collection finished: 1757326036.397664\n",
      "stock code: sh601168 data collection finished: 1757326036.4007294\n",
      "stock code: sz000987 data collection finished: 1757326036.4017296\n",
      "stock code: sh605277 data collection finished: 1757326036.4040918\n",
      "stock code: sh600675 data collection finished: 1757326036.4078963\n",
      "stock code: sz002389 data collection finished: 1757326036.4078963\n",
      "stock code: sh600735 data collection finished: 1757326037.0897853\n",
      "stock code: sz002726 data collection finished: 1757326037.0930796\n",
      "stock code: sh603669 data collection finished: 1757326037.0930796\n",
      "stock code: sh603707 data collection finished: 1757326037.0967922\n",
      "stock code: sz000927 data collection finished: 1757326037.0967922\n",
      "stock code: sh600057 data collection finished: 1757326037.491064\n"
     ]
    }
   ],
   "source": [
    "aspls = np.array_split(stock_codes, logical_cpus)\n",
    "# 然后每个子数组是numpy数组，可以转成列表\n",
    "chunked_list = [arr.tolist() for arr in aspls]\n",
    "\n",
    "process_lock = multiprocessing.Lock()\n",
    "\n",
    "stock_data = []\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=logical_cpus) as executor:\n",
    "    futures = [executor.submit(stock_data_getter, stock_codes_ls, formatted_start_day, formatted_today)\n",
    "        for stock_codes_ls in chunked_list]\n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            result = future.result() \n",
    "            stock_data += result\n",
    "        except Exception as e:\n",
    "            print(\"Error in got results thread:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c20bd998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3032 3032\n"
     ]
    }
   ],
   "source": [
    "print(len(stock_data),len(stock_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bc7036f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date   open  close   high    low    volume  turnover_rate\n",
      "0   2025-07-21  36.90  39.70  39.80  35.70  129218.0           1.88\n",
      "1   2025-07-22  39.00  42.80  43.67  38.40  201174.0           2.93\n",
      "2   2025-07-23  41.69  40.81  44.49  40.51  190418.0           2.77\n",
      "3   2025-07-24  41.40  40.89  41.62  40.02  125022.0           1.82\n",
      "4   2025-07-25  40.80  40.30  41.53  39.84  105944.0           1.54\n",
      "5   2025-07-28  40.35  40.44  40.82  39.94   93719.0           1.36\n",
      "6   2025-07-29  40.22  41.69  42.53  39.40  143769.0           2.09\n",
      "7   2025-07-30  41.24  41.08  42.12  40.32   96728.0           1.41\n",
      "8   2025-07-31  41.50  40.98  42.86  40.38  158025.0           2.30\n",
      "9   2025-08-01  40.90  41.32  42.20  40.44   94210.0           1.37\n",
      "10  2025-08-04  41.27  41.44  41.66  39.60   96278.0           1.40\n",
      "11  2025-08-05  41.25  42.06  42.88  40.71  101397.0           1.48\n",
      "12  2025-08-06  42.26  45.44  46.27  42.00  161031.0           2.35\n",
      "13  2025-08-07  44.50  42.26  45.98  42.00  141268.0           2.06\n",
      "14  2025-08-08  41.66  42.28  42.49  40.98   86730.0           1.26\n",
      "15  2025-08-11  42.00  42.55  43.12  41.51   74398.0           1.08\n",
      "16  2025-08-12  42.37  42.18  42.50  41.53   66239.0           0.96\n",
      "17  2025-08-13  42.28  44.49  45.13  42.04  101837.0           1.48\n",
      "18  2025-08-14  44.49  46.13  47.37  44.00  102046.0           1.49\n",
      "19  2025-08-15  46.13  46.00  46.73  45.03   77713.0           1.13\n",
      "20  2025-08-18  45.97  44.40  46.20  43.04  111983.0           1.63\n",
      "21  2025-08-19  44.01  43.29  44.94  43.23   70875.0           1.03\n",
      "22  2025-08-20  43.13  43.27  44.58  42.00   76996.0           1.12\n",
      "23  2025-08-21  43.26  43.74  44.40  42.73   72981.0           1.06\n",
      "24  2025-08-22  43.43  42.26  43.88  42.00  113282.0           1.65\n",
      "25  2025-08-25  42.28  42.67  43.23  41.70  109754.0           1.60\n",
      "26  2025-08-26  42.54  42.20  43.10  42.10   68289.0           0.99\n",
      "27  2025-08-27  42.08  40.73  42.65  40.70   78461.0           1.14\n",
      "28  2025-08-28  40.50  39.36  40.90  37.55  173771.0           2.53\n",
      "29  2025-08-29  39.18  40.26  40.80  39.02   97166.0           1.41\n",
      "30  2025-09-01  40.03  41.86  42.55  39.60  120944.0           1.76\n",
      "31  2025-09-02  41.87  41.50  42.67  41.10   84957.0           1.24\n",
      "32  2025-09-03  41.86  41.21  42.55  40.71   52668.0           0.77\n",
      "33  2025-09-04  41.21  39.35  41.65  38.76   94188.0           1.37\n",
      "34  2025-09-05  39.31  40.08  40.26  38.66   64507.0           0.94\n",
      "35  2025-09-08  40.12  39.60  40.48  38.81   60468.0           0.88\n"
     ]
    }
   ],
   "source": [
    "print(stock_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd604b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdaspls = np.array_split(np.array(stock_data,  dtype=object), physical_cpus)\n",
    "# sd_chunked_list = [arr.tolist() for arr in sdaspls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9dfd9ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_code: sz002584 result: 超跌反转+资金异动型 \n",
      " \n",
      "stock_code: sh600589 result: 超跌反转+资金异动型 \n",
      " \n",
      "stock_code: sh603990 result: 超跌反转+资金异动型 \n",
      " \n",
      "stock_code: sz000777 result: 超跌反转+资金异动型 \n",
      " \n",
      "stock_code: sh600173 result: 趋势启动+量价齐升型 \n",
      " \n",
      "stock_code: sz002255 result: 超跌反转+资金异动型 \n",
      " \n",
      "stock_code: sh603121 result: 超跌反转+资金异动型 \n",
      " \n",
      "stock_code: sh605488 result: 超跌反转+资金异动型 \n",
      " \n",
      "stock_code: sz002977 result: 超跌反转+资金异动型 \n",
      " \n",
      "wrong count 0\n"
     ]
    }
   ],
   "source": [
    "def check_parameter(stock_codes_ls):\n",
    "    count = 0\n",
    "    for stock_code, stock_zh_df in stock_codes_ls:\n",
    "        open = stock_zh_df[\"open\"]\n",
    "        close = stock_zh_df[\"close\"]\n",
    "        high = stock_zh_df[\"high\"]\n",
    "        low = stock_zh_df[\"low\"]\n",
    "        volume = stock_zh_df[\"volume\"]\n",
    "        turnover = stock_zh_df[\"turnover_rate\"]\n",
    "\n",
    "        ma5 = talib.EMA(close, timeperiod=5)\n",
    "        ma10 = talib.EMA(close, timeperiod=10)\n",
    "        vol_ma5 = talib.EMA(volume, timeperiod=5)\n",
    "        atr = talib.NATR(high, low, close, timeperiod=8)\n",
    "        atr_ma = talib.EMA(atr, timeperiod=5)\n",
    "        macd, macdsignal, macdhist = talib.MACD(close, fastperiod=7, slowperiod=18, signalperiod=6)\n",
    "\n",
    "        rsi = talib.RSI(close, timeperiod=14)  # RSI相对强弱指标\n",
    "        cci = talib.CCI(high, low, close, timeperiod=20)  # 顺势指标\n",
    "        # money_flow = (2*close - low - high) / (high - low) * volume  # 简易资金流\n",
    "        money_flow = talib.MFI(high, low, close, volume, timeperiod=9)\n",
    "        # money_flow_max= money_flow.shift(3).rolling(4).max().iloc[-1]\n",
    "        # turnover_mean= money_flow.shift(1).rolling(5).mean().iloc[-1]\n",
    "        today_candlestick = abs(close.iloc[-3] - open.iloc[-3])\n",
    "        yesterday_candlestick = abs(close.iloc[-4] - open.iloc[-4])\n",
    "        \n",
    "        if (close.iloc[-3] > ma5.iloc[-3] and (ma5.iloc[3] > ma10.iloc[-3]  or (ma5.iloc[-3] > ma5.iloc[-4] > ma5.iloc[-5]))) and \\\n",
    "            rsi.iloc[-3] < 60 and atr.iloc[-3]  > atr_ma.iloc[-3] and open.iloc[-3]  < close.iloc[-3]  * 1.03 and \\\n",
    "                volume.iloc[-3] > vol_ma5.iloc[-3] * 1.5 and turnover.iloc[-3] > 3 and \\\n",
    "                (macd.iloc[-3] > macdsignal.iloc[-3] and macd.iloc[-4] < macdsignal.iloc[-4] and macdhist.iloc[-3] > abs(macdhist.iloc[-4])):\n",
    "            if close.iloc[-1] > close.iloc[-2]:\n",
    "                print(f\"\"\"stock_code: {stock_code} result: 趋势启动+量价齐升型 \\n \"\"\")\n",
    "            else:\n",
    "                count += 1\n",
    "        elif (rsi.iloc[-3] < 35) and (cci.iloc[-3] < -100) and \\\n",
    "            today_candlestick > 0.5 * yesterday_candlestick and turnover.iloc[-1] > 3 and \\\n",
    "            money_flow.iloc[-3] > money_flow.iloc[-4]:\n",
    "            if close.iloc[-1] > close.iloc[-2]:\n",
    "                print(f\"\"\"stock_code: {stock_code} result: 超跌反转+资金异动型 \\n \"\"\")\n",
    "            else:\n",
    "                count += 1\n",
    "    print(\"wrong count\", count)\n",
    "\n",
    "check_parameter(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "007a97d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ProcessPoolExecutor(max_workers=physical_cpus) as executor:\n",
    "#     futures = [executor.submit(check_parameter, sd_ls)\n",
    "#         for sd_ls in sd_chunked_list]\n",
    "#     for future in as_completed(futures):\n",
    "#         try:\n",
    "#             future.result() \n",
    "#         except Exception as e:\n",
    "#             print(\"Error in process:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8447d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_code: sz002734 result: 趋势启动+量价齐升型 \n",
      " \n",
      "stock_code: sh600620 result: 趋势启动+量价齐升型 \n",
      " \n",
      "stock_code: sh603079 result: 趋势启动+量价齐升型 \n",
      " \n",
      "stock_code: sh600391 result: 超跌反转+资金异动型 \n",
      " \n",
      "stock_code: sh603016 result: 趋势启动+量价齐升型 \n",
      " \n",
      "stock_code: sz002389 result: 超跌反转+资金异动型 \n",
      " \n",
      "stock_code: sz000822 result: 趋势启动+量价齐升型 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "def run_analysis(stock_codes_ls):\n",
    "    res_ls = []\n",
    "    for stock_code, stock_zh_df in stock_codes_ls:\n",
    "        open = stock_zh_df[\"open\"]\n",
    "        close = stock_zh_df[\"close\"]\n",
    "        high = stock_zh_df[\"high\"]\n",
    "        low = stock_zh_df[\"low\"]\n",
    "        volume = stock_zh_df[\"volume\"]\n",
    "        turnover = stock_zh_df[\"turnover_rate\"]\n",
    "\n",
    "        ma5 = talib.EMA(close, timeperiod=5)\n",
    "        ma10 = talib.EMA(close, timeperiod=10)\n",
    "        vol_ma5 = talib.EMA(volume, timeperiod=5)\n",
    "        atr = talib.NATR(high, low, close, timeperiod=8)\n",
    "        atr_ma = talib.EMA(atr, timeperiod=5)\n",
    "        macd, macdsignal, macdhist = talib.MACD(close, fastperiod=7, slowperiod=18, signalperiod=6)#快速EMA：6~8，慢速EMA：15~20，信号线：5~7\n",
    "\n",
    "        rsi = talib.RSI(close, timeperiod=14)  # RSI相对强弱指标\n",
    "        cci = talib.CCI(high, low, close, timeperiod=20)  # 顺势指标\n",
    "        # money_flow = (2*close - low - high) / (high - low) * volume  # 简易资金流\n",
    "        money_flow = talib.MFI(high, low, close, volume, timeperiod=9)\n",
    "        # money_flow_max= money_flow.shift(1).rolling(4).max().iloc[-1]\n",
    "        # turnover_mean= money_flow.shift(1).rolling(5).mean().iloc[-1]\n",
    "        today_candlestick = abs(close.iloc[-1] - open.iloc[-1])\n",
    "        yesterday_candlestick = abs(close.iloc[-2] - open.iloc[-2])\n",
    "\n",
    "        if close.iloc[-1] > ma5.iloc[-1] and (ma5.iloc[1] > ma10.iloc[-1] or (ma5.iloc[-1] > ma5.iloc[-2] > ma5.iloc[-3])) and \\\n",
    "                rsi.iloc[-1] < 60 and atr.iloc[-1]  > atr_ma.iloc[-1] and open.iloc[-1]  < close.iloc[-1]  * 1.03 and \\\n",
    "                volume.iloc[-1] >= vol_ma5.iloc[-1] * 1.5 and turnover.iloc[-1] > 3 and \\\n",
    "                macd.iloc[-1] > macdsignal.iloc[-1] and macd.iloc[-2] < macdsignal.iloc[-2] and macdhist.iloc[-1] > 0.6 * abs(macdhist.iloc[-2]):\n",
    "            res_ls.append(f\"\"\"stock_code: {stock_code} result: 趋势启动+量价齐升型 \\n \"\"\")\n",
    "        elif (rsi.iloc[-1] < 35) and (cci.iloc[-1] < -100) and \\\n",
    "            today_candlestick > 0.5 * yesterday_candlestick and turnover.iloc[-1] > 3 and \\\n",
    "            money_flow.iloc[-1] > money_flow.iloc[-2]:\n",
    "            res_ls.append(f\"\"\"stock_code: {stock_code} result: 超跌反转+资金异动型 \\n \"\"\")\n",
    "\n",
    "    for result in res_ls:\n",
    "        print(result)\n",
    "    # with open('today_suggestions.txt', 'a', encoding='utf-8') as today_suggestions,open('history_suggestions.txt', 'a', encoding='utf-8') as history_suggestions:\n",
    "    #     for result in res_ls:\n",
    "    #         today_suggestions.write(result)\n",
    "    #         history_suggestions.write(result)\n",
    "\n",
    "\n",
    "run_analysis(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0d37891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ProcessPoolExecutor(max_workers=physical_cpus) as executor:\n",
    "#     futures = [executor.submit(run_analysis, args=(stock_codes_ls, process_lock))\n",
    "#         for stock_codes_ls in chunked_list]\n",
    "#     for future in as_completed(futures):\n",
    "#         try:\n",
    "#             future.result() \n",
    "#         except Exception as e:\n",
    "#             print(\"Error in thread:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccd560fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validate_proxy(proxies, result_queue):\n",
    "#     \"\"\"验证代理有效性 [6]()\"\"\"\n",
    "#     test_url = \"http://icanhazip.com\"   # 测试网站 \n",
    "#     for proxy in proxies:\n",
    "#         # print(\"Testing proxy:\", proxy)\n",
    "#         try:\n",
    "#             start_time = time.time() \n",
    "#             resp = requests.get(test_url,  proxies=proxy, timeout=5)\n",
    "#             latency = int((time.time()  - start_time))  # 计算延迟 \n",
    "#             # print(resp.status_code, type(resp.status_code),resp.text,proxy)\n",
    "#             if resp.status_code  == 200:\n",
    "#                 result_queue.put((latency, proxy))\n",
    "#         except Exception:\n",
    "#             pass\n",
    "\n",
    "# proxies_map = []\n",
    "# response = requests.get('https://api.proxyscrape.com/v4/free-proxy-list/get?request=display_proxies&proxy_format=protocolipport&format=text',  timeout=30)\n",
    "# if response.status_code == 200:\n",
    "#     proxies = response.text.replace(\"socks4\",  \"https\")\n",
    "#     proxies_ls = [proxy for proxy in proxies.split('\\r\\n')  if proxy != \"\"]\n",
    "\n",
    "#     for url in proxies_ls:\n",
    "#         try:\n",
    "#             # 按 \"://\" 分割协议和地址（最多分割1次）\n",
    "#             protocol, _address = url.split('://',  1)\n",
    "#             if protocol == \"http\":\n",
    "#                 proxies_map.append({protocol: url})\n",
    "#         except ValueError:\n",
    "#             # 处理无效格式（如缺少 ://）\n",
    "#             print(f\"跳过无效URL: {url}\")\n",
    "#     print(proxies_map)\n",
    "# aspls = np.array_split(proxies_map, logical_cpus)\n",
    "# # 然后每个子数组是numpy数组，可以转成列表\n",
    "# chunked_list = [arr.tolist() for arr in aspls]\n",
    "\n",
    "# validate_proxies_queue = queue.Queue()\n",
    "# validate_proxies_ls = []\n",
    "\n",
    "# process_lock = multiprocessing.Lock()\n",
    "\n",
    "# with ThreadPoolExecutor(max_workers=logical_cpus) as executor:\n",
    "#     futures = [executor.submit(validate_proxy, proxies, validate_proxies_queue)\n",
    "#         for proxies in chunked_list]\n",
    "#     for future in as_completed(futures):\n",
    "#         try:\n",
    "#             future.result()\n",
    "#         except Exception as e:\n",
    "#             print(\"Error in got results thread:\", e)\n",
    "\n",
    "# while not validate_proxies_queue.empty():\n",
    "#     validate_proxies_ls.append(validate_proxies_queue.get())\n",
    "\n",
    "# validate_proxies_ls =sorted(validate_proxies_ls, key=lambda x: x[0])\n",
    "# for i in validate_proxies_ls:\n",
    "#     validate_proxies_queue.put(i[1])\n",
    "\n",
    "# print(validate_proxies_ls)\n",
    "# print(len(validate_proxies_ls))\n",
    "# print(validate_proxies_queue.empty())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76582855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stock_data_getter_with_proxies(stock_codes, formatted_start_day, formatted_today, validate_proxies_queue):\n",
    "#     res_ls = []\n",
    "#     if validate_proxies_queue.empty():\n",
    "#         return []\n",
    "#     proxy = validate_proxies_queue.get()\n",
    "#     i = 0\n",
    "#     while i < len(stock_codes):\n",
    "#         time.sleep(0.8) #avoid abandon from remote\n",
    "#         stock_code = stock_codes[i]\n",
    "#         i += 1\n",
    "#         stock_zh_a_hist_df = kline_daily.stock_zh_a_hist_with_proxy(symbol=stock_code, start_date=formatted_start_day, end_date=formatted_today, proxy={\"http\":proxy[\"http\"]})\n",
    "#         if stock_zh_a_hist_df is None:\n",
    "#             if validate_proxies_queue.empty():\n",
    "#                 print(\"proxy ran out\")\n",
    "#                 return []\n",
    "#             proxy = validate_proxies_queue.get()\n",
    "#             i -= 1\n",
    "#         elif stock_zh_a_hist_df.empty:\n",
    "#             print(\"wrong code:\",stock_code)\n",
    "#         else:\n",
    "#             res_ls.append((stock_code, stock_zh_a_hist_df))\n",
    "#     print(\"stock code:\",stock_codes[-1],\"data collection finished:\", time.time())\n",
    "#     return res_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0f4d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect_and_analyze_data([\"000001\",\"000002\"], log_phy_ratio, formatted_start_day, formatted_today, lock, run_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d038d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sd = ak.stock_zh_a_hist(symbol=\"000001\", period=\"daily\", start_date=formatted_start_day, end_date=formatted_today, adjust=\"\")\n",
    "# print(sd)\n",
    "# df_shanghai = ak.index_zh_a_hist( \n",
    "#     symbol=\"000001\",      # 上证指数代码（固定为000001）\n",
    "#     period=\"daily\",       # 数据周期：daily（日线）、weekly（周线）、monthly（月线）\n",
    "#     start_date=\"20200101\", # 起始日期（格式：YYYYMMDD）\n",
    "#     end_date=\"20250904\",   # 结束日期（默认为当前日期）\n",
    "# )\n",
    "\n",
    "# # 查看前5行数据 \n",
    "# print(df_shanghai.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18438774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_mainboard_stocks_ak():\n",
    "#     \"\"\"使用akshare获取主板股票列表\"\"\"\n",
    "#     # 获取所有上市公司的基本信息\n",
    "#     stock_info = ak.stock_info_a_code_name()\n",
    "    \n",
    "#     # 筛选主板股票\n",
    "#     mainboard_stocks = stock_info[stock_info['code'].str.startswith(('600', '601', '603', '605', '000', '002'))]\n",
    "    \n",
    "#     return mainboard_stocks\n",
    "\n",
    "# # 获取主板股票\n",
    "# mainboard_stocks_ak = get_mainboard_stocks_ak()\n",
    "# print(mainboard_stocks_ak.head())\n",
    "# mainboard_stocks_ak.to_csv('mainboard_stocks.csv', index=False, encoding='utf-8-sig')\n",
    "# def add_stock_prefix(code):\n",
    "#     code_str = str(code).zfill(6)  # 确保代码为6位字符串 \n",
    "#     if code_str.startswith('6'):    # 上证\n",
    "#         return 'sh' + code_str\n",
    "#     elif code_str.startswith(('0',  '3')):  # 深证\n",
    "#         return 'sz' + code_str \n",
    "#     return code_str  # 其他情况保留原格式 \n",
    "# mainboard_stocks_ak['code'] = mainboard_stocks_ak['code'].apply(add_stock_prefix)\n",
    "# mainboard_stocks_ak.to_csv('mainboard_stocks_with_prefix.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a612a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # date=\"20200331\"; choice of {\"XXXX0331\", \"XXXX0630\", \"XXXX0930\", \"XXXX1231\"}; 从 20081231 开始\n",
    "# stock_yjyg_em_df = ak.stock_yjyg_em(date=\"20250630\")\n",
    "# stock_yjyg_em_df_sorted_desc = stock_yjyg_em_df.sort_values(by=stock_yjyg_em_df.columns[6], ascending=False) #'业绩变动幅度'\n",
    "# # print(stock_yjyg_em_df_sorted_desc.head(10))\n",
    "# print(stock_yjyg_em_df_sorted_desc.iloc[:, [1,6]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "856e634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ProxyManager:\n",
    "#     \"\"\"代理IP管理器\"\"\"\n",
    "\n",
    "#     def __init__(self, proxy_api_url, max_retry=3):\n",
    "#         self.proxy_api_url = proxy_api_url\n",
    "#         self.max_retry = max_retry\n",
    "\n",
    "#     def get_valid_proxy(self):\n",
    "#         \"\"\"获取有效的代理IP\"\"\"\n",
    "#         for attempt in range(self.max_retry):\n",
    "#             try:\n",
    "#                 resp = requests.get(self.proxy_api_url, timeout=5)\n",
    "#                 proxy_json = resp.json()\n",
    "#                 proxy_data = proxy_json[\"data\"][0]\n",
    "#                 server = proxy_data[\"server\"]\n",
    "#                 ip, port = server.split(\":\")\n",
    "#                 proxy = {\"http\": f\"http://{ip}:{port}\", \"https\": f\"http://{ip}:{port}\"}\n",
    "\n",
    "#                 # 验证代理可用性\n",
    "#                 test_url = \"http://quote.eastmoney.com\"\n",
    "#                 test = requests.get(test_url, proxies=proxy, timeout=5)\n",
    "#                 if test.status_code == 200:\n",
    "#                     print(f\"代理可用: {ip}:{port}\")\n",
    "#                     return proxy\n",
    "#             except Exception as e:\n",
    "#                 print(f\"获取代理失败，第{attempt + 1}次尝试: {e}\")\n",
    "\n",
    "#         print(f\"未能获取有效代理\")\n",
    "#         return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
