{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28ce91c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d79ebb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace \n",
    "from datetime import datetime, timedelta\n",
    "import akshare as ak\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "# import threading\n",
    "import threading\n",
    "import queue\n",
    "import psutil\n",
    "import time\n",
    "import talib\n",
    "from concurrent.futures  import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "# import kline_daily\n",
    "import requests\n",
    "# import cloudscraper\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9653e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stock_zh_a_hist_tx(\n",
    "        symbol: str = \"sz000001\",\n",
    "        start_date: str = \"19000101\",\n",
    "        end_date: str = \"20500101\",\n",
    "        adjust: str = \"\",\n",
    "        timeout: float = None,\n",
    ") -> pd.DataFrame:\n",
    "    url = \"https://proxy.finance.qq.com/ifzqgtimg/appstock/app/newfqkline/get\"\n",
    "    big_df = pd.DataFrame()\n",
    "    params = {\n",
    "        \"_var\": f\"kline_day{adjust}{int(start_date[:4])}\",\n",
    "        \"param\": f\"{symbol},day,{start_date},{end_date},640,{adjust}\",\n",
    "        \"r\": \"0.8205512681390605\",\n",
    "    }\n",
    "    r = requests.get(url, params=params, timeout=timeout)\n",
    "    data_text = r.text\n",
    "    data_json = ak.utils.demjson.decode(data_text[data_text.find(\"={\") + 1:])[\"data\"][\n",
    "        symbol\n",
    "    ]\n",
    "    if \"day\" in data_json.keys():\n",
    "        temp_df = pd.DataFrame(data_json[\"day\"])\n",
    "    elif \"hfqday\" in data_json.keys():\n",
    "        temp_df = pd.DataFrame(data_json[\"hfqday\"])\n",
    "    else:\n",
    "        temp_df = pd.DataFrame(data_json[\"qfqday\"])\n",
    "    big_df = pd.concat([big_df, temp_df], ignore_index=True)\n",
    "    \n",
    "    big_df = big_df.iloc[:, [0,1,2,3,4,5,7]]\n",
    "    big_df.columns = [\"date\", \"open\", \"close\", \"high\", \"low\", \"volume\",\"turnover_rate\"]\n",
    "    big_df[\"date\"] = pd.to_datetime(big_df[\"date\"], errors=\"coerce\").dt.date\n",
    "    big_df[\"open\"] = pd.to_numeric(big_df[\"open\"], errors=\"coerce\")\n",
    "    big_df[\"close\"] = pd.to_numeric(big_df[\"close\"], errors=\"coerce\")\n",
    "    big_df[\"high\"] = pd.to_numeric(big_df[\"high\"], errors=\"coerce\")\n",
    "    big_df[\"low\"] = pd.to_numeric(big_df[\"low\"], errors=\"coerce\")\n",
    "    big_df[\"volume\"] = pd.to_numeric(big_df[\"volume\"], errors=\"coerce\")\n",
    "    big_df[\"turnover_rate\"] = pd.to_numeric(big_df[\"turnover_rate\"], errors=\"coerce\")\n",
    "    big_df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    big_df.index = pd.to_datetime(big_df[\"date\"])\n",
    "    big_df = big_df[start_date:end_date]\n",
    "    big_df.reset_index(inplace=True, drop=True)\n",
    "    return big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a6dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置 root logger：记录 DEBUG 及以上到 all.log \n",
    "logging.basicConfig( \n",
    "    filename='all.log', \n",
    "    filemode='a',\n",
    "    level=logging.DEBUG,\n",
    "    encoding='utf-8',\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    " \n",
    "# 创建 error logger\n",
    "error_logger = logging.getLogger('error_logger') \n",
    "error_logger.setLevel(logging.ERROR)   # 设置 error_logger 只处理 ERROR 及以上级别 \n",
    " \n",
    "# 创建 error.log  的 handler\n",
    "error_handler = logging.FileHandler('error.log',  encoding='utf-8') \n",
    "error_handler.setLevel(logging.ERROR) \n",
    " \n",
    "# 设置 error 日志格式\n",
    "error_formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "error_handler.setFormatter(error_formatter) \n",
    " \n",
    "# 添加 handler 到 error_logger \n",
    "error_logger.addHandler(error_handler) \n",
    " \n",
    "# 防止日志重复传播到 root logger（避免 error 日志出现在 all.log  中两次）\n",
    "error_logger.propagate  = False\n",
    " \n",
    "# 测试日志\n",
    "logging.debug(' 这是 root logger 的 DEBUG 日志，写入 all.log') \n",
    "logging.info(' 这是 root logger 的 INFO 日志，写入 all.log') \n",
    "logging.critical(' 这是 root logger 的 Critical 日志，写入 all.log') \n",
    "error_logger.error(' 这是一个 ERROR 日志，写入 error.log  和 all.log （除非 propagate=False）')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "135e595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.error(\"dwdw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3b0d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_len = len(df)\n",
    "physical_cpus = psutil.cpu_count(logical=False)\n",
    "logical_cpus = psutil.cpu_count(logical=True)\n",
    "\n",
    "log_phy_ratio = int(logical_cpus/physical_cpus)\n",
    "# phy_cpu_length = int(total_len/physical_cpus)\n",
    "args = SimpleNamespace(\n",
    "    datedelta = 50,\n",
    "    start_epochs = 8\n",
    "    )\n",
    "today = datetime.now()\n",
    "start_day = today - timedelta(days=args.datedelta)\n",
    "test_day = today - timedelta(days=1)\n",
    "\n",
    "# 格式化日期为YYYYMMDD格式\n",
    "# formatted_today = today.strftime('%Y%m%d')\n",
    "# formatted_test_day = test_day.strftime('%Y%m%d')\n",
    "# formatted_start_day = start_day.strftime('%Y%m%d')\n",
    "\n",
    "# 格式化日期为YYYY-MM-DD格式\n",
    "formatted_today = today.strftime('%Y-%m-%d')\n",
    "formatted_test_day = test_day.strftime('%Y-%m-%d')\n",
    "formatted_start_day = start_day.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fcc91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('today_suggestions.txt', 'w', encoding='utf-8') as today_suggestions,open('history_suggestions.txt', 'a', encoding='utf-8') as history_suggestions:\n",
    "    today_suggestions.write(formatted_today + \"!!!!!!!!~~~~~~~~~~~~~~\\n\")\n",
    "    history_suggestions.write(formatted_today + \"!!!!!!!!!!!~~~~~~~~~~~~\\n\")\n",
    "# df = pd.read_csv('data.csv',  dtype={0: str})\n",
    "df = pd.read_csv('mainboard_stocks_with_prefix.csv', dtype={'code': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10e31cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sz000001</td>\n",
       "      <td>平安银行</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sz000002</td>\n",
       "      <td>万  科Ａ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sz000004</td>\n",
       "      <td>*ST国华</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sz000006</td>\n",
       "      <td>深振业Ａ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sz000007</td>\n",
       "      <td>全新好</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code   name\n",
       "0  sz000001   平安银行\n",
       "1  sz000002  万  科Ａ\n",
       "2  sz000004  *ST国华\n",
       "3  sz000006   深振业Ａ\n",
       "4  sz000007    全新好"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_codes = list(set(df['code']))\n",
    "print(len(df) == len(stock_codes))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe2b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_data_getter(stock_codes, formatted_start_day, formatted_today):\n",
    "    res_ls = []\n",
    "    for stock_code in stock_codes:\n",
    "        # time.sleep(0.8) #avoid abandon from remote\n",
    "        try:\n",
    "            stock_zh_a_hist_df = stock_zh_a_hist_tx(symbol=stock_code, start_date=formatted_start_day, end_date=formatted_today)\n",
    "            if stock_zh_a_hist_df.empty:\n",
    "                print(\"wrong code:\",stock_code)\n",
    "            else:\n",
    "                res_ls.append((stock_code, stock_zh_a_hist_df))\n",
    "        except Exception as e:\n",
    "            print(\"exception:\",e)\n",
    "            logging.error(e)\n",
    "    print(\"stock code:\",stock_codes[-1],\"data collection finished:\", time.time())\n",
    "    return res_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcdb32ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock code: sh600032 data collection finished: 1757937360.2860157\n",
      "stock code: sz002057 data collection finished: 1757937361.09877\n",
      "stock code: sh600518 data collection finished: 1757937361.6132576\n",
      "stock code: sz002317 data collection finished: 1757937361.6497006\n",
      "stock code: sh605228 data collection finished: 1757937361.8756914\n",
      "stock code: sh601860 data collection finished: 1757937362.6665685\n",
      "stock code: sh603893 data collection finished: 1757937362.8571439\n",
      "stock code: sz002864 data collection finished: 1757937363.599314\n",
      "stock code: sh600026 data collection finished: 1757937364.0000756\n",
      "stock code: sh600509 data collection finished: 1757937364.1512256\n",
      "stock code: sh601108 data collection finished: 1757937364.2880127\n",
      "stock code: sh600743 data collection finished: 1757937364.3080797\n",
      "stock code: sz000615 data collection finished: 1757937364.3533225\n",
      "stock code: sh603305 data collection finished: 1757937364.4133377\n",
      "stock code: sh600637 data collection finished: 1757937364.5010297\n",
      "stock code: sh600526 data collection finished: 1757937364.6657965\n",
      "stock code: sh600022 data collection finished: 1757937364.6657965\n",
      "stock code: sz002184 data collection finished: 1757937364.939514\n",
      "stock code: sh600519 data collection finished: 1757937365.0853786\n",
      "stock code: sz002291 data collection finished: 1757937365.1287477\n",
      "stock code: sz002659 data collection finished: 1757937365.3985524\n",
      "stock code: sh601068 data collection finished: 1757937365.5280325\n",
      "stock code: sz000056 data collection finished: 1757937365.5280325\n",
      "stock code: sh603100 data collection finished: 1757937365.6304483\n",
      "stock code: sh603308 data collection finished: 1757937365.632448\n",
      "stock code: sz000020 data collection finished: 1757937365.6417816\n",
      "stock code: sz002439 data collection finished: 1757937366.2058465\n",
      "stock code: sh600860 data collection finished: 1757937366.3142042\n",
      "stock code: sh600480 data collection finished: 1757937366.3149307\n",
      "stock code: sh605128 data collection finished: 1757937366.3168247\n",
      "stock code: sz002822 data collection finished: 1757937366.3168247\n",
      "stock code: sh603324 data collection finished: 1757937366.3168247\n"
     ]
    }
   ],
   "source": [
    "aspls = np.array_split(stock_codes, logical_cpus)\n",
    "# 然后每个子数组是numpy数组，可以转成列表\n",
    "chunked_list = [arr.tolist() for arr in aspls]\n",
    "\n",
    "process_lock = multiprocessing.Lock()\n",
    "\n",
    "stock_data = []\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=logical_cpus) as executor:\n",
    "    futures = [executor.submit(stock_data_getter, stock_codes_ls, formatted_start_day, formatted_today)\n",
    "        for stock_codes_ls in chunked_list]\n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            result = future.result() \n",
    "            stock_data += result\n",
    "        except Exception as e:\n",
    "            print(\"Error in got results thread:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c20bd998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3032 3032\n"
     ]
    }
   ],
   "source": [
    "print(len(stock_data),len(stock_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bc7036f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date   open  close   high    low    volume  turnover_rate\n",
      "0   2025-07-28   8.95   9.13   9.24   8.90  165183.0           3.15\n",
      "1   2025-07-29   9.13   9.09   9.19   9.00   99758.0           1.90\n",
      "2   2025-07-30   9.03   9.10   9.19   8.92   94011.0           1.79\n",
      "3   2025-07-31   9.10   8.95   9.16   8.88   78414.0           1.50\n",
      "4   2025-08-01   8.96   9.34   9.43   8.96  150270.0           2.87\n",
      "5   2025-08-04   9.21  10.02  10.07   9.12  237687.0           4.53\n",
      "6   2025-08-05  10.08   9.96  10.15   9.90  115941.0           2.21\n",
      "7   2025-08-06   9.96   9.85   9.96   9.70  102045.0           1.95\n",
      "8   2025-08-07   9.87   9.97  10.10   9.86  120922.0           2.31\n",
      "9   2025-08-08   9.97  10.14  10.16   9.77  118638.0           2.26\n",
      "10  2025-08-11  10.32  10.04  10.35   9.96  106575.0           2.03\n",
      "11  2025-08-12  10.04   9.97  10.04   9.86   74657.0           1.42\n",
      "12  2025-08-13   9.97  10.10  10.26   9.91  117231.0           2.24\n",
      "13  2025-08-14  10.11  10.05  10.34   9.99   95895.0           1.83\n",
      "14  2025-08-15  10.04   9.83  10.04   9.78  103681.0           1.98\n",
      "15  2025-08-18   9.84   9.86   9.95   9.69  117415.0           2.24\n",
      "16  2025-08-19   9.86   9.74   9.94   9.73   80087.0           1.53\n",
      "17  2025-08-20   9.71   9.78   9.93   9.70   83135.0           1.59\n",
      "18  2025-08-21   9.78   9.82   9.86   9.65   74557.0           1.42\n",
      "19  2025-08-22   9.84   9.81   9.84   9.71   79365.0           1.51\n",
      "20  2025-08-25   9.81   9.94  10.14   9.69  134735.0           2.57\n",
      "21  2025-08-26   9.89  10.00  10.24   9.82  155233.0           2.96\n",
      "22  2025-08-27  10.01   9.97  10.30   9.94  162967.0           3.11\n",
      "23  2025-08-28   9.98   9.83  10.04   9.48  141499.0           2.70\n",
      "24  2025-08-29   9.81   9.90  10.02   9.74   69864.0           1.33\n",
      "25  2025-09-01   9.91  10.89  10.89   9.84  233754.0           4.46\n",
      "26  2025-09-02  10.89  10.87  11.06  10.70  253133.0           4.83\n",
      "27  2025-09-03  10.89  10.72  11.27  10.67  158638.0           3.02\n",
      "28  2025-09-04  10.89  10.60  10.97  10.38  147056.0           2.80\n",
      "29  2025-09-05  10.65  10.98  11.00  10.51  111052.0           2.12\n",
      "30  2025-09-08  11.10  11.88  12.08  10.92  326516.0           6.23\n",
      "31  2025-09-09  11.76  13.07  13.07  11.76  386702.0           7.37\n",
      "32  2025-09-10  13.02  12.15  13.07  11.99  561404.0          10.70\n",
      "33  2025-09-11  12.00  11.95  12.29  11.51  297822.0           5.68\n",
      "34  2025-09-12  11.95  11.65  12.09  11.60  197234.0           3.76\n",
      "35  2025-09-15  11.73  11.88  12.50  11.57  283341.0           5.40\n"
     ]
    }
   ],
   "source": [
    "print(stock_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd604b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdaspls = np.array_split(np.array(stock_data,  dtype=object), physical_cpus)\n",
    "# sd_chunked_list = [arr.tolist() for arr in sdaspls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dfd9ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXstock_code: sh605058 wrong result: 趋势启动+量价齐升型 \n",
      " \n",
      "wrong count 1\n"
     ]
    }
   ],
   "source": [
    "def check_parameter(stock_codes_ls):\n",
    "    count = 0\n",
    "    for stock_code, stock_zh_df in stock_codes_ls:\n",
    "        open = stock_zh_df[\"open\"]\n",
    "        close = stock_zh_df[\"close\"]\n",
    "        high = stock_zh_df[\"high\"]\n",
    "        low = stock_zh_df[\"low\"]\n",
    "        volume = stock_zh_df[\"volume\"]\n",
    "        turnover = stock_zh_df[\"turnover_rate\"]\n",
    "\n",
    "        ma5 = talib.EMA(close, timeperiod=5)\n",
    "        ma10 = talib.EMA(close, timeperiod=10)\n",
    "        vol_ma5 = talib.EMA(volume, timeperiod=5)\n",
    "        atr = talib.NATR(high, low, close, timeperiod=8)\n",
    "        atr_ma = talib.EMA(atr, timeperiod=5)\n",
    "        macd, macdsignal, macdhist = talib.MACD(close, fastperiod=7, slowperiod=18, signalperiod=6)\n",
    "\n",
    "        rsi = talib.RSI(close, timeperiod=14)  # RSI相对强弱指标\n",
    "        cci = talib.CCI(high, low, close, timeperiod=20)  # 顺势指标\n",
    "        # money_flow = (2*close - low - high) / (high - low) * volume  # 简易资金流\n",
    "        money_flow = talib.MFI(high, low, close, volume, timeperiod=9)\n",
    "        # money_flow_max= money_flow.shift(3).rolling(4).max().iloc[-1]\n",
    "        # turnover_mean= money_flow.shift(1).rolling(5).mean().iloc[-1]\n",
    "        today_candlestick = abs(close.iloc[-3] - open.iloc[-3])\n",
    "        yesterday_candlestick = abs(close.iloc[-4] - open.iloc[-4])\n",
    "        \n",
    "        if (close.iloc[-3] > ma5.iloc[-3] and (ma5.iloc[3] > ma10.iloc[-3]  or (ma5.iloc[-3] > ma5.iloc[-4] > ma5.iloc[-5]))) and \\\n",
    "            rsi.iloc[-3] < 60 and atr.iloc[-3]  > atr_ma.iloc[-3] and open.iloc[-3]  < close.iloc[-3]  * 1.03 and \\\n",
    "                volume.iloc[-3] > vol_ma5.iloc[-3] * 1.5 and turnover.iloc[-3] > 3 and \\\n",
    "                (macd.iloc[-3] > macdsignal.iloc[-3] and macd.iloc[-4] < macdsignal.iloc[-4] and macdhist.iloc[-3] > abs(macdhist.iloc[-4])):\n",
    "            if close.iloc[-1] > close.iloc[-2]:\n",
    "                print(f\"\"\"stock_code: {stock_code} result: 趋势启动+量价齐升型 \\n \"\"\")\n",
    "            else:\n",
    "                print(f\"\"\"XXXXXXstock_code: {stock_code} wrong result: 趋势启动+量价齐升型 \\n \"\"\")\n",
    "                count += 1\n",
    "        elif (rsi.iloc[-3] < 35) and (cci.iloc[-3] < -100) and \\\n",
    "            today_candlestick > 0.5 * yesterday_candlestick and turnover.iloc[-1] > 3 and \\\n",
    "            money_flow.iloc[-3] > money_flow.iloc[-4]:\n",
    "            if close.iloc[-1] > close.iloc[-2]:\n",
    "                print(f\"\"\"stock_code: {stock_code} result: 超跌反转+资金异动型 \\n \"\"\")\n",
    "            else:\n",
    "                print(f\"\"\"XXXXXXstock_code: {stock_code} wrong result: 超跌反转+资金异动型 \\n \"\"\")\n",
    "                count += 1\n",
    "    print(\"wrong count\", count)\n",
    "\n",
    "check_parameter(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "007a97d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ProcessPoolExecutor(max_workers=physical_cpus) as executor:\n",
    "#     futures = [executor.submit(check_parameter, sd_ls)\n",
    "#         for sd_ls in sd_chunked_list]\n",
    "#     for future in as_completed(futures):\n",
    "#         try:\n",
    "#             future.result() \n",
    "#         except Exception as e:\n",
    "#             print(\"Error in process:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a8447d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_code: sz002149 result: 超跌反转+资金异动型 \n",
      " \n",
      "stock_code: sz002174 result: 超跌反转+资金异动型 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "def run_analysis(stock_codes_ls):\n",
    "    res_ls = []\n",
    "    for stock_code, stock_zh_df in stock_codes_ls:\n",
    "        open = stock_zh_df[\"open\"]\n",
    "        close = stock_zh_df[\"close\"]\n",
    "        high = stock_zh_df[\"high\"]\n",
    "        low = stock_zh_df[\"low\"]\n",
    "        volume = stock_zh_df[\"volume\"]\n",
    "        turnover = stock_zh_df[\"turnover_rate\"]\n",
    "\n",
    "        ma5 = talib.EMA(close, timeperiod=5)\n",
    "        ma10 = talib.EMA(close, timeperiod=10)\n",
    "        vol_ma5 = talib.EMA(volume, timeperiod=5)\n",
    "        atr = talib.NATR(high, low, close, timeperiod=8)\n",
    "        atr_ma = talib.EMA(atr, timeperiod=5)\n",
    "        macd, macdsignal, macdhist = talib.MACD(close, fastperiod=7, slowperiod=18, signalperiod=6)#快速EMA：6~8，慢速EMA：15~20，信号线：5~7\n",
    "\n",
    "        rsi = talib.RSI(close, timeperiod=14)  # RSI相对强弱指标\n",
    "        cci = talib.CCI(high, low, close, timeperiod=20)  # 顺势指标\n",
    "        # money_flow = (2*close - low - high) / (high - low) * volume  # 简易资金流\n",
    "        money_flow = talib.MFI(high, low, close, volume, timeperiod=9)\n",
    "        # money_flow_max= money_flow.shift(1).rolling(4).max().iloc[-1]\n",
    "        # turnover_mean= money_flow.shift(1).rolling(5).mean().iloc[-1]\n",
    "        today_candlestick = abs(close.iloc[-1] - open.iloc[-1])\n",
    "        yesterday_candlestick = abs(close.iloc[-2] - open.iloc[-2])\n",
    "\n",
    "        if close.iloc[-1] > ma5.iloc[-1] and (ma5.iloc[1] > ma10.iloc[-1] or (ma5.iloc[-1] > ma5.iloc[-2] > ma5.iloc[-3])) and \\\n",
    "                rsi.iloc[-1] < 60 and atr.iloc[-1]  > atr_ma.iloc[-1] and open.iloc[-1]  < close.iloc[-1]  * 1.03 and \\\n",
    "                volume.iloc[-1] >= vol_ma5.iloc[-1] * 1.5 and turnover.iloc[-1] > 3 and \\\n",
    "                macd.iloc[-1] > macdsignal.iloc[-1] and macd.iloc[-2] < macdsignal.iloc[-2] and macdhist.iloc[-1] > 0.6 * abs(macdhist.iloc[-2]):\n",
    "            res_ls.append(f\"\"\"stock_code: {stock_code} result: 趋势启动+量价齐升型 \\n \"\"\")\n",
    "        elif (rsi.iloc[-1] < 35) and (cci.iloc[-1] < -100) and \\\n",
    "            today_candlestick > 0.5 * yesterday_candlestick and turnover.iloc[-1] > 3 and \\\n",
    "            money_flow.iloc[-1] > money_flow.iloc[-2]:\n",
    "            res_ls.append(f\"\"\"stock_code: {stock_code} result: 超跌反转+资金异动型 \\n \"\"\")\n",
    "\n",
    "    for result in res_ls:\n",
    "        print(result)\n",
    "    # with open('today_suggestions.txt', 'a', encoding='utf-8') as today_suggestions,open('history_suggestions.txt', 'a', encoding='utf-8') as history_suggestions:\n",
    "    #     for result in res_ls:\n",
    "    #         today_suggestions.write(result)\n",
    "    #         history_suggestions.write(result)\n",
    "\n",
    "\n",
    "run_analysis(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0d37891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ProcessPoolExecutor(max_workers=physical_cpus) as executor:\n",
    "#     futures = [executor.submit(run_analysis, args=(stock_codes_ls, process_lock))\n",
    "#         for stock_codes_ls in chunked_list]\n",
    "#     for future in as_completed(futures):\n",
    "#         try:\n",
    "#             future.result() \n",
    "#         except Exception as e:\n",
    "#             print(\"Error in thread:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccd560fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validate_proxy(proxies, result_queue):\n",
    "#     \"\"\"验证代理有效性 [6]()\"\"\"\n",
    "#     test_url = \"http://icanhazip.com\"   # 测试网站 \n",
    "#     for proxy in proxies:\n",
    "#         # print(\"Testing proxy:\", proxy)\n",
    "#         try:\n",
    "#             start_time = time.time() \n",
    "#             resp = requests.get(test_url,  proxies=proxy, timeout=5)\n",
    "#             latency = int((time.time()  - start_time))  # 计算延迟 \n",
    "#             # print(resp.status_code, type(resp.status_code),resp.text,proxy)\n",
    "#             if resp.status_code  == 200:\n",
    "#                 result_queue.put((latency, proxy))\n",
    "#         except Exception:\n",
    "#             pass\n",
    "\n",
    "# proxies_map = []\n",
    "# response = requests.get('https://api.proxyscrape.com/v4/free-proxy-list/get?request=display_proxies&proxy_format=protocolipport&format=text',  timeout=30)\n",
    "# if response.status_code == 200:\n",
    "#     proxies = response.text.replace(\"socks4\",  \"https\")\n",
    "#     proxies_ls = [proxy for proxy in proxies.split('\\r\\n')  if proxy != \"\"]\n",
    "\n",
    "#     for url in proxies_ls:\n",
    "#         try:\n",
    "#             # 按 \"://\" 分割协议和地址（最多分割1次）\n",
    "#             protocol, _address = url.split('://',  1)\n",
    "#             if protocol == \"http\":\n",
    "#                 proxies_map.append({protocol: url})\n",
    "#         except ValueError:\n",
    "#             # 处理无效格式（如缺少 ://）\n",
    "#             print(f\"跳过无效URL: {url}\")\n",
    "#     print(proxies_map)\n",
    "# aspls = np.array_split(proxies_map, logical_cpus)\n",
    "# # 然后每个子数组是numpy数组，可以转成列表\n",
    "# chunked_list = [arr.tolist() for arr in aspls]\n",
    "\n",
    "# validate_proxies_queue = queue.Queue()\n",
    "# validate_proxies_ls = []\n",
    "\n",
    "# process_lock = multiprocessing.Lock()\n",
    "\n",
    "# with ThreadPoolExecutor(max_workers=logical_cpus) as executor:\n",
    "#     futures = [executor.submit(validate_proxy, proxies, validate_proxies_queue)\n",
    "#         for proxies in chunked_list]\n",
    "#     for future in as_completed(futures):\n",
    "#         try:\n",
    "#             future.result()\n",
    "#         except Exception as e:\n",
    "#             print(\"Error in got results thread:\", e)\n",
    "\n",
    "# while not validate_proxies_queue.empty():\n",
    "#     validate_proxies_ls.append(validate_proxies_queue.get())\n",
    "\n",
    "# validate_proxies_ls =sorted(validate_proxies_ls, key=lambda x: x[0])\n",
    "# for i in validate_proxies_ls:\n",
    "#     validate_proxies_queue.put(i[1])\n",
    "\n",
    "# print(validate_proxies_ls)\n",
    "# print(len(validate_proxies_ls))\n",
    "# print(validate_proxies_queue.empty())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76582855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stock_data_getter_with_proxies(stock_codes, formatted_start_day, formatted_today, validate_proxies_queue):\n",
    "#     res_ls = []\n",
    "#     if validate_proxies_queue.empty():\n",
    "#         return []\n",
    "#     proxy = validate_proxies_queue.get()\n",
    "#     i = 0\n",
    "#     while i < len(stock_codes):\n",
    "#         time.sleep(0.8) #avoid abandon from remote\n",
    "#         stock_code = stock_codes[i]\n",
    "#         i += 1\n",
    "#         stock_zh_a_hist_df = kline_daily.stock_zh_a_hist_with_proxy(symbol=stock_code, start_date=formatted_start_day, end_date=formatted_today, proxy={\"http\":proxy[\"http\"]})\n",
    "#         if stock_zh_a_hist_df is None:\n",
    "#             if validate_proxies_queue.empty():\n",
    "#                 print(\"proxy ran out\")\n",
    "#                 return []\n",
    "#             proxy = validate_proxies_queue.get()\n",
    "#             i -= 1\n",
    "#         elif stock_zh_a_hist_df.empty:\n",
    "#             print(\"wrong code:\",stock_code)\n",
    "#         else:\n",
    "#             res_ls.append((stock_code, stock_zh_a_hist_df))\n",
    "#     print(\"stock code:\",stock_codes[-1],\"data collection finished:\", time.time())\n",
    "#     return res_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0f4d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect_and_analyze_data([\"000001\",\"000002\"], log_phy_ratio, formatted_start_day, formatted_today, lock, run_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d038d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sd = ak.stock_zh_a_hist(symbol=\"000001\", period=\"daily\", start_date=formatted_start_day, end_date=formatted_today, adjust=\"\")\n",
    "# print(sd)\n",
    "# df_shanghai = ak.index_zh_a_hist( \n",
    "#     symbol=\"000001\",      # 上证指数代码（固定为000001）\n",
    "#     period=\"daily\",       # 数据周期：daily（日线）、weekly（周线）、monthly（月线）\n",
    "#     start_date=\"20200101\", # 起始日期（格式：YYYYMMDD）\n",
    "#     end_date=\"20250904\",   # 结束日期（默认为当前日期）\n",
    "# )\n",
    "\n",
    "# # 查看前5行数据 \n",
    "# print(df_shanghai.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18438774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_mainboard_stocks_ak():\n",
    "#     \"\"\"使用akshare获取主板股票列表\"\"\"\n",
    "#     # 获取所有上市公司的基本信息\n",
    "#     stock_info = ak.stock_info_a_code_name()\n",
    "    \n",
    "#     # 筛选主板股票\n",
    "#     mainboard_stocks = stock_info[stock_info['code'].str.startswith(('600', '601', '603', '605', '000', '002'))]\n",
    "    \n",
    "#     return mainboard_stocks\n",
    "\n",
    "# # 获取主板股票\n",
    "# mainboard_stocks_ak = get_mainboard_stocks_ak()\n",
    "# print(mainboard_stocks_ak.head())\n",
    "# mainboard_stocks_ak.to_csv('mainboard_stocks.csv', index=False, encoding='utf-8-sig')\n",
    "# def add_stock_prefix(code):\n",
    "#     code_str = str(code).zfill(6)  # 确保代码为6位字符串 \n",
    "#     if code_str.startswith('6'):    # 上证\n",
    "#         return 'sh' + code_str\n",
    "#     elif code_str.startswith(('0',  '3')):  # 深证\n",
    "#         return 'sz' + code_str \n",
    "#     return code_str  # 其他情况保留原格式 \n",
    "# mainboard_stocks_ak['code'] = mainboard_stocks_ak['code'].apply(add_stock_prefix)\n",
    "# mainboard_stocks_ak.to_csv('mainboard_stocks_with_prefix.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a612a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # date=\"20200331\"; choice of {\"XXXX0331\", \"XXXX0630\", \"XXXX0930\", \"XXXX1231\"}; 从 20081231 开始\n",
    "# stock_yjyg_em_df = ak.stock_yjyg_em(date=\"20250630\")\n",
    "# stock_yjyg_em_df_sorted_desc = stock_yjyg_em_df.sort_values(by=stock_yjyg_em_df.columns[6], ascending=False) #'业绩变动幅度'\n",
    "# # print(stock_yjyg_em_df_sorted_desc.head(10))\n",
    "# print(stock_yjyg_em_df_sorted_desc.iloc[:, [1,6]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "856e634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ProxyManager:\n",
    "#     \"\"\"代理IP管理器\"\"\"\n",
    "\n",
    "#     def __init__(self, proxy_api_url, max_retry=3):\n",
    "#         self.proxy_api_url = proxy_api_url\n",
    "#         self.max_retry = max_retry\n",
    "\n",
    "#     def get_valid_proxy(self):\n",
    "#         \"\"\"获取有效的代理IP\"\"\"\n",
    "#         for attempt in range(self.max_retry):\n",
    "#             try:\n",
    "#                 resp = requests.get(self.proxy_api_url, timeout=5)\n",
    "#                 proxy_json = resp.json()\n",
    "#                 proxy_data = proxy_json[\"data\"][0]\n",
    "#                 server = proxy_data[\"server\"]\n",
    "#                 ip, port = server.split(\":\")\n",
    "#                 proxy = {\"http\": f\"http://{ip}:{port}\", \"https\": f\"http://{ip}:{port}\"}\n",
    "\n",
    "#                 # 验证代理可用性\n",
    "#                 test_url = \"http://quote.eastmoney.com\"\n",
    "#                 test = requests.get(test_url, proxies=proxy, timeout=5)\n",
    "#                 if test.status_code == 200:\n",
    "#                     print(f\"代理可用: {ip}:{port}\")\n",
    "#                     return proxy\n",
    "#             except Exception as e:\n",
    "#                 print(f\"获取代理失败，第{attempt + 1}次尝试: {e}\")\n",
    "\n",
    "#         print(f\"未能获取有效代理\")\n",
    "#         return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
