{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28ce91c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d79ebb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace \n",
    "from datetime import datetime, timedelta\n",
    "import akshare as ak\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "# import threading\n",
    "import threading\n",
    "import queue\n",
    "import psutil\n",
    "import time\n",
    "import talib\n",
    "from concurrent.futures  import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "# import kline_daily\n",
    "import requests\n",
    "# import cloudscraper\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9653e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stock_zh_a_hist_tx(\n",
    "        symbol: str = \"sz000001\",\n",
    "        start_date: str = \"19000101\",\n",
    "        end_date: str = \"20500101\",\n",
    "        adjust: str = \"\",\n",
    "        timeout: float = None,\n",
    ") -> pd.DataFrame:\n",
    "    url = \"https://proxy.finance.qq.com/ifzqgtimg/appstock/app/newfqkline/get\"\n",
    "    big_df = pd.DataFrame()\n",
    "    params = {\n",
    "        \"_var\": f\"kline_day{adjust}{int(start_date[:4])}\",\n",
    "        \"param\": f\"{symbol},day,{start_date},{end_date},640,{adjust}\",\n",
    "        \"r\": \"0.8205512681390605\",\n",
    "    }\n",
    "    r = requests.get(url, params=params, timeout=timeout)\n",
    "    data_text = r.text\n",
    "    data_json = ak.utils.demjson.decode(data_text[data_text.find(\"={\") + 1:])[\"data\"][\n",
    "        symbol\n",
    "    ]\n",
    "    if \"day\" in data_json.keys():\n",
    "        temp_df = pd.DataFrame(data_json[\"day\"])\n",
    "    elif \"hfqday\" in data_json.keys():\n",
    "        temp_df = pd.DataFrame(data_json[\"hfqday\"])\n",
    "    else:\n",
    "        temp_df = pd.DataFrame(data_json[\"qfqday\"])\n",
    "    big_df = pd.concat([big_df, temp_df], ignore_index=True)\n",
    "    \n",
    "    big_df = big_df.iloc[:, [0,1,2,3,4,5,7]]\n",
    "    big_df.columns = [\"date\", \"open\", \"close\", \"high\", \"low\", \"volume\",\"turnover_rate\"]\n",
    "    big_df[\"date\"] = pd.to_datetime(big_df[\"date\"], errors=\"coerce\").dt.date\n",
    "    big_df[\"open\"] = pd.to_numeric(big_df[\"open\"], errors=\"coerce\")\n",
    "    big_df[\"close\"] = pd.to_numeric(big_df[\"close\"], errors=\"coerce\")\n",
    "    big_df[\"high\"] = pd.to_numeric(big_df[\"high\"], errors=\"coerce\")\n",
    "    big_df[\"low\"] = pd.to_numeric(big_df[\"low\"], errors=\"coerce\")\n",
    "    big_df[\"volume\"] = pd.to_numeric(big_df[\"volume\"], errors=\"coerce\")\n",
    "    big_df[\"turnover_rate\"] = pd.to_numeric(big_df[\"turnover_rate\"], errors=\"coerce\")\n",
    "    big_df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    big_df.index = pd.to_datetime(big_df[\"date\"])\n",
    "    big_df = big_df[start_date:end_date]\n",
    "    big_df.reset_index(inplace=True, drop=True)\n",
    "    return big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a6dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置 root logger：记录 DEBUG 及以上到 all.log \n",
    "logging.basicConfig( \n",
    "    filename='all.log', \n",
    "    filemode='a',\n",
    "    level=logging.DEBUG,\n",
    "    encoding='utf-8',\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    " \n",
    "# 创建 error logger\n",
    "error_logger = logging.getLogger('error_logger') \n",
    "error_logger.setLevel(logging.ERROR)   # 设置 error_logger 只处理 ERROR 及以上级别 \n",
    " \n",
    "# 创建 error.log  的 handler\n",
    "error_handler = logging.FileHandler('error.log',  encoding='utf-8') \n",
    "error_handler.setLevel(logging.ERROR) \n",
    " \n",
    "# 设置 error 日志格式\n",
    "error_formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "error_handler.setFormatter(error_formatter) \n",
    " \n",
    "# 添加 handler 到 error_logger \n",
    "error_logger.addHandler(error_handler) \n",
    " \n",
    "# 防止日志重复传播到 root logger（避免 error 日志出现在 all.log  中两次）\n",
    "error_logger.propagate  = False\n",
    " \n",
    "# 测试日志\n",
    "logging.debug(' 这是 root logger 的 DEBUG 日志，写入 all.log') \n",
    "logging.info(' 这是 root logger 的 INFO 日志，写入 all.log') \n",
    "logging.critical(' 这是 root logger 的 Critical 日志，写入 all.log') \n",
    "error_logger.error(' 这是一个 ERROR 日志，写入 error.log  和 all.log （除非 propagate=False）')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "135e595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.error(\"dwdw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3b0d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_len = len(df)\n",
    "physical_cpus = psutil.cpu_count(logical=False)\n",
    "logical_cpus = psutil.cpu_count(logical=True)\n",
    "\n",
    "log_phy_ratio = int(logical_cpus/physical_cpus)\n",
    "# phy_cpu_length = int(total_len/physical_cpus)\n",
    "args = SimpleNamespace(\n",
    "    datedelta = 50,\n",
    "    start_epochs = 8\n",
    "    )\n",
    "today = datetime.now()\n",
    "start_day = today - timedelta(days=args.datedelta)\n",
    "test_day = today - timedelta(days=1)\n",
    "\n",
    "# 格式化日期为YYYYMMDD格式\n",
    "# formatted_today = today.strftime('%Y%m%d')\n",
    "# formatted_test_day = test_day.strftime('%Y%m%d')\n",
    "# formatted_start_day = start_day.strftime('%Y%m%d')\n",
    "\n",
    "# 格式化日期为YYYY-MM-DD格式\n",
    "formatted_today = today.strftime('%Y-%m-%d')\n",
    "formatted_test_day = test_day.strftime('%Y-%m-%d')\n",
    "formatted_start_day = start_day.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fcc91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('today_suggestions.txt', 'w', encoding='utf-8') as today_suggestions,open('history_suggestions.txt', 'a', encoding='utf-8') as history_suggestions:\n",
    "    today_suggestions.write(formatted_today + \"!!!!!!!!~~~~~~~~~~~~~~\\n\")\n",
    "    history_suggestions.write(formatted_today + \"!!!!!!!!!!!~~~~~~~~~~~~\\n\")\n",
    "# df = pd.read_csv('data.csv',  dtype={0: str})\n",
    "df = pd.read_csv('mainboard_stocks_with_prefix.csv', dtype={'code': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10e31cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sz000001</td>\n",
       "      <td>平安银行</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sz000002</td>\n",
       "      <td>万  科Ａ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sz000004</td>\n",
       "      <td>*ST国华</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sz000006</td>\n",
       "      <td>深振业Ａ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sz000007</td>\n",
       "      <td>全新好</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code   name\n",
       "0  sz000001   平安银行\n",
       "1  sz000002  万  科Ａ\n",
       "2  sz000004  *ST国华\n",
       "3  sz000006   深振业Ａ\n",
       "4  sz000007    全新好"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_codes = list(set(df['code']))\n",
    "print(len(df) == len(stock_codes))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe2b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_data_getter(stock_codes, formatted_start_day, formatted_today):\n",
    "    res_ls = []\n",
    "    for stock_code in stock_codes:\n",
    "        # time.sleep(0.8) #avoid abandon from remote\n",
    "        try:\n",
    "            stock_zh_a_hist_df = stock_zh_a_hist_tx(symbol=stock_code, start_date=formatted_start_day, end_date=formatted_today)\n",
    "            if stock_zh_a_hist_df.empty:\n",
    "                print(\"wrong code:\",stock_code)\n",
    "            else:\n",
    "                res_ls.append((stock_code, stock_zh_a_hist_df))\n",
    "        except Exception as e:\n",
    "            print(\"exception:\",e)\n",
    "            logging.error(e)\n",
    "    print(\"stock code:\",stock_codes[-1],\"data collection finished:\", time.time())\n",
    "    return res_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcdb32ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock code: sz002441 data collection finished: 1757757262.9157975\n",
      "stock code: sh603050 data collection finished: 1757757263.3767917\n",
      "stock code: sh601163 data collection finished: 1757757265.9998057\n",
      "stock code: sz000682 data collection finished: 1757757266.129347\n",
      "stock code: sz000628 data collection finished: 1757757266.255019\n",
      "stock code: sh603337 data collection finished: 1757757266.2631454\n",
      "stock code: sh600771 data collection finished: 1757757266.4047306\n",
      "stock code: sz002287 data collection finished: 1757757266.4259179\n",
      "stock code: sh600103 data collection finished: 1757757266.630181\n",
      "stock code: sh600188 data collection finished: 1757757266.7386987\n",
      "stock code: sh605056 data collection finished: 1757757266.7386987\n",
      "stock code: sz002700 data collection finished: 1757757267.2146292\n",
      "stock code: sh603391 data collection finished: 1757757267.760487\n",
      "stock code: sh600775 data collection finished: 1757757267.7990763\n",
      "stock code: sz000789 data collection finished: 1757757267.8795164\n",
      "stock code: sh603599 data collection finished: 1757757267.9033773\n",
      "stock code: sz000550 data collection finished: 1757757268.31289\n",
      "stock code: sz000417 data collection finished: 1757757268.3835382\n",
      "stock code: sh600171 data collection finished: 1757757268.5756137\n",
      "stock code: sh600211 data collection finished: 1757757268.5874002\n",
      "stock code: sh603960 data collection finished: 1757757268.8973503\n",
      "stock code: sz000963 data collection finished: 1757757268.9846683\n",
      "stock code: sh600749 data collection finished: 1757757269.1411185\n",
      "stock code: sz000922 data collection finished: 1757757269.1773663\n",
      "stock code: sh600238 data collection finished: 1757757269.243487\n",
      "stock code: sh605208 data collection finished: 1757757269.3567991\n",
      "stock code: sh603669 data collection finished: 1757757269.3776326\n",
      "stock code: sz002177 data collection finished: 1757757269.4050672\n",
      "stock code: sh605319 data collection finished: 1757757269.4199078\n",
      "stock code:stock code: sh600050 data collection finished: 1757757269.8445814\n",
      " sz000561 data collection finished: 1757757269.8445814\n",
      "stock code: sz002651 data collection finished: 1757757271.0869427\n"
     ]
    }
   ],
   "source": [
    "aspls = np.array_split(stock_codes, logical_cpus)\n",
    "# 然后每个子数组是numpy数组，可以转成列表\n",
    "chunked_list = [arr.tolist() for arr in aspls]\n",
    "\n",
    "process_lock = multiprocessing.Lock()\n",
    "\n",
    "stock_data = []\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=logical_cpus) as executor:\n",
    "    futures = [executor.submit(stock_data_getter, stock_codes_ls, formatted_start_day, formatted_today)\n",
    "        for stock_codes_ls in chunked_list]\n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            result = future.result() \n",
    "            stock_data += result\n",
    "        except Exception as e:\n",
    "            print(\"Error in got results thread:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c20bd998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3032 3032\n"
     ]
    }
   ],
   "source": [
    "print(len(stock_data),len(stock_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bc7036f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  open  close  high   low    volume  turnover_rate\n",
      "0   2025-07-25  5.45   5.35  5.47  5.33  257391.0           2.77\n",
      "1   2025-07-28  5.35   5.31  5.37  5.30  154028.0           1.66\n",
      "2   2025-07-29  5.31   5.31  5.33  5.23  147258.0           1.58\n",
      "3   2025-07-30  5.28   5.25  5.30  5.22  140793.0           1.51\n",
      "4   2025-07-31  5.23   5.18  5.27  5.17  152883.0           1.64\n",
      "5   2025-08-01  5.18   5.20  5.22  5.17  100463.0           1.08\n",
      "6   2025-08-04  5.17   5.23  5.23  5.16   90083.0           0.97\n",
      "7   2025-08-05  5.23   5.25  5.26  5.22  100576.0           1.08\n",
      "8   2025-08-06  5.23   5.29  5.30  5.22  135905.0           1.46\n",
      "9   2025-08-07  5.32   5.30  5.34  5.26  132517.0           1.43\n",
      "10  2025-08-08  5.30   5.31  5.34  5.26  138828.0           1.49\n",
      "11  2025-08-11  5.31   5.36  5.36  5.27  160481.0           1.73\n",
      "12  2025-08-12  5.36   5.34  5.37  5.31  107616.0           1.16\n",
      "13  2025-08-13  5.32   5.38  5.38  5.31  182066.0           1.96\n",
      "14  2025-08-14  5.38   5.22  5.39  5.22  217912.0           2.34\n",
      "15  2025-08-15  5.21   5.33  5.34  5.21  171410.0           1.84\n",
      "16  2025-08-18  5.35   5.42  5.43  5.34  251898.0           2.71\n",
      "17  2025-08-19  5.42   5.44  5.47  5.39  183043.0           1.97\n",
      "18  2025-08-20  5.42   5.50  5.50  5.39  211952.0           2.28\n",
      "19  2025-08-21  5.51   5.50  5.59  5.45  276745.0           2.98\n",
      "20  2025-08-22  5.49   5.49  5.51  5.42  186383.0           2.00\n",
      "21  2025-08-25  5.50   5.50  5.58  5.45  232339.0           2.50\n",
      "22  2025-08-26  5.50   5.61  5.66  5.46  333186.0           3.58\n",
      "23  2025-08-27  5.64   5.43  5.64  5.42  272948.0           2.94\n",
      "24  2025-08-28  5.42   5.49  5.52  5.27  257452.0           2.77\n",
      "25  2025-08-29  5.47   5.34  5.49  5.31  240327.0           2.58\n",
      "26  2025-09-01  5.33   5.34  5.44  5.28  192257.0           2.07\n",
      "27  2025-09-02  5.33   5.26  5.34  5.18  238397.0           2.56\n",
      "28  2025-09-03  5.29   5.12  5.30  5.11  164565.0           1.77\n",
      "29  2025-09-04  5.15   5.13  5.20  5.07  177458.0           1.91\n",
      "30  2025-09-05  5.16   5.25  5.25  5.13  157923.0           1.70\n",
      "31  2025-09-08  5.26   5.25  5.27  5.21  143694.0           1.55\n",
      "32  2025-09-09  5.26   5.18  5.26  5.16  145163.0           1.56\n",
      "33  2025-09-10  5.18   5.14  5.21  5.13  131119.0           1.41\n",
      "34  2025-09-11  5.15   5.24  5.24  5.08  171418.0           1.84\n",
      "35  2025-09-12  5.24   5.19  5.25  5.18  118935.0           1.28\n"
     ]
    }
   ],
   "source": [
    "print(stock_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd604b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdaspls = np.array_split(np.array(stock_data,  dtype=object), physical_cpus)\n",
    "# sd_chunked_list = [arr.tolist() for arr in sdaspls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dfd9ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_code: sz002900 result: 超跌反转+资金异动型 \n",
      " \n",
      "wrong count 1\n"
     ]
    }
   ],
   "source": [
    "def check_parameter(stock_codes_ls):\n",
    "    count = 0\n",
    "    for stock_code, stock_zh_df in stock_codes_ls:\n",
    "        open = stock_zh_df[\"open\"]\n",
    "        close = stock_zh_df[\"close\"]\n",
    "        high = stock_zh_df[\"high\"]\n",
    "        low = stock_zh_df[\"low\"]\n",
    "        volume = stock_zh_df[\"volume\"]\n",
    "        turnover = stock_zh_df[\"turnover_rate\"]\n",
    "\n",
    "        ma5 = talib.EMA(close, timeperiod=5)\n",
    "        ma10 = talib.EMA(close, timeperiod=10)\n",
    "        vol_ma5 = talib.EMA(volume, timeperiod=5)\n",
    "        atr = talib.NATR(high, low, close, timeperiod=8)\n",
    "        atr_ma = talib.EMA(atr, timeperiod=5)\n",
    "        macd, macdsignal, macdhist = talib.MACD(close, fastperiod=7, slowperiod=18, signalperiod=6)\n",
    "\n",
    "        rsi = talib.RSI(close, timeperiod=14)  # RSI相对强弱指标\n",
    "        cci = talib.CCI(high, low, close, timeperiod=20)  # 顺势指标\n",
    "        # money_flow = (2*close - low - high) / (high - low) * volume  # 简易资金流\n",
    "        money_flow = talib.MFI(high, low, close, volume, timeperiod=9)\n",
    "        # money_flow_max= money_flow.shift(3).rolling(4).max().iloc[-1]\n",
    "        # turnover_mean= money_flow.shift(1).rolling(5).mean().iloc[-1]\n",
    "        today_candlestick = abs(close.iloc[-3] - open.iloc[-3])\n",
    "        yesterday_candlestick = abs(close.iloc[-4] - open.iloc[-4])\n",
    "        \n",
    "        if (close.iloc[-3] > ma5.iloc[-3] and (ma5.iloc[3] > ma10.iloc[-3]  or (ma5.iloc[-3] > ma5.iloc[-4] > ma5.iloc[-5]))) and \\\n",
    "            rsi.iloc[-3] < 60 and atr.iloc[-3]  > atr_ma.iloc[-3] and open.iloc[-3]  < close.iloc[-3]  * 1.03 and \\\n",
    "                volume.iloc[-3] > vol_ma5.iloc[-3] * 1.5 and turnover.iloc[-3] > 3 and \\\n",
    "                (macd.iloc[-3] > macdsignal.iloc[-3] and macd.iloc[-4] < macdsignal.iloc[-4] and macdhist.iloc[-3] > abs(macdhist.iloc[-4])):\n",
    "            if close.iloc[-1] > close.iloc[-2]:\n",
    "                print(f\"\"\"stock_code: {stock_code} result: 趋势启动+量价齐升型 \\n \"\"\")\n",
    "            else:\n",
    "                count += 1\n",
    "        elif (rsi.iloc[-3] < 35) and (cci.iloc[-3] < -100) and \\\n",
    "            today_candlestick > 0.5 * yesterday_candlestick and turnover.iloc[-1] > 3 and \\\n",
    "            money_flow.iloc[-3] > money_flow.iloc[-4]:\n",
    "            if close.iloc[-1] > close.iloc[-2]:\n",
    "                print(f\"\"\"stock_code: {stock_code} result: 超跌反转+资金异动型 \\n \"\"\")\n",
    "            else:\n",
    "                count += 1\n",
    "    print(\"wrong count\", count)\n",
    "\n",
    "check_parameter(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "007a97d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ProcessPoolExecutor(max_workers=physical_cpus) as executor:\n",
    "#     futures = [executor.submit(check_parameter, sd_ls)\n",
    "#         for sd_ls in sd_chunked_list]\n",
    "#     for future in as_completed(futures):\n",
    "#         try:\n",
    "#             future.result() \n",
    "#         except Exception as e:\n",
    "#             print(\"Error in process:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a8447d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_code: sh603855 result: 趋势启动+量价齐升型 \n",
      " \n",
      "stock_code: sz002660 result: 趋势启动+量价齐升型 \n",
      " \n",
      "stock_code: sh603535 result: 趋势启动+量价齐升型 \n",
      " \n",
      "stock_code: sh600219 result: 趋势启动+量价齐升型 \n",
      " \n",
      "stock_code: sh600769 result: 趋势启动+量价齐升型 \n",
      " \n",
      "stock_code: sh605488 result: 趋势启动+量价齐升型 \n",
      " \n",
      "stock_code: sh600157 result: 趋势启动+量价齐升型 \n",
      " \n",
      "stock_code: sh603038 result: 趋势启动+量价齐升型 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "def run_analysis(stock_codes_ls):\n",
    "    res_ls = []\n",
    "    for stock_code, stock_zh_df in stock_codes_ls:\n",
    "        open = stock_zh_df[\"open\"]\n",
    "        close = stock_zh_df[\"close\"]\n",
    "        high = stock_zh_df[\"high\"]\n",
    "        low = stock_zh_df[\"low\"]\n",
    "        volume = stock_zh_df[\"volume\"]\n",
    "        turnover = stock_zh_df[\"turnover_rate\"]\n",
    "\n",
    "        ma5 = talib.EMA(close, timeperiod=5)\n",
    "        ma10 = talib.EMA(close, timeperiod=10)\n",
    "        vol_ma5 = talib.EMA(volume, timeperiod=5)\n",
    "        atr = talib.NATR(high, low, close, timeperiod=8)\n",
    "        atr_ma = talib.EMA(atr, timeperiod=5)\n",
    "        macd, macdsignal, macdhist = talib.MACD(close, fastperiod=7, slowperiod=18, signalperiod=6)#快速EMA：6~8，慢速EMA：15~20，信号线：5~7\n",
    "\n",
    "        rsi = talib.RSI(close, timeperiod=14)  # RSI相对强弱指标\n",
    "        cci = talib.CCI(high, low, close, timeperiod=20)  # 顺势指标\n",
    "        # money_flow = (2*close - low - high) / (high - low) * volume  # 简易资金流\n",
    "        money_flow = talib.MFI(high, low, close, volume, timeperiod=9)\n",
    "        # money_flow_max= money_flow.shift(1).rolling(4).max().iloc[-1]\n",
    "        # turnover_mean= money_flow.shift(1).rolling(5).mean().iloc[-1]\n",
    "        today_candlestick = abs(close.iloc[-1] - open.iloc[-1])\n",
    "        yesterday_candlestick = abs(close.iloc[-2] - open.iloc[-2])\n",
    "\n",
    "        if close.iloc[-1] > ma5.iloc[-1] and (ma5.iloc[1] > ma10.iloc[-1] or (ma5.iloc[-1] > ma5.iloc[-2] > ma5.iloc[-3])) and \\\n",
    "                rsi.iloc[-1] < 60 and atr.iloc[-1]  > atr_ma.iloc[-1] and open.iloc[-1]  < close.iloc[-1]  * 1.03 and \\\n",
    "                volume.iloc[-1] >= vol_ma5.iloc[-1] * 1.5 and turnover.iloc[-1] > 3 and \\\n",
    "                macd.iloc[-1] > macdsignal.iloc[-1] and macd.iloc[-2] < macdsignal.iloc[-2] and macdhist.iloc[-1] > 0.6 * abs(macdhist.iloc[-2]):\n",
    "            res_ls.append(f\"\"\"stock_code: {stock_code} result: 趋势启动+量价齐升型 \\n \"\"\")\n",
    "        elif (rsi.iloc[-1] < 35) and (cci.iloc[-1] < -100) and \\\n",
    "            today_candlestick > 0.5 * yesterday_candlestick and turnover.iloc[-1] > 3 and \\\n",
    "            money_flow.iloc[-1] > money_flow.iloc[-2]:\n",
    "            res_ls.append(f\"\"\"stock_code: {stock_code} result: 超跌反转+资金异动型 \\n \"\"\")\n",
    "\n",
    "    for result in res_ls:\n",
    "        print(result)\n",
    "    # with open('today_suggestions.txt', 'a', encoding='utf-8') as today_suggestions,open('history_suggestions.txt', 'a', encoding='utf-8') as history_suggestions:\n",
    "    #     for result in res_ls:\n",
    "    #         today_suggestions.write(result)\n",
    "    #         history_suggestions.write(result)\n",
    "\n",
    "\n",
    "run_analysis(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0d37891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ProcessPoolExecutor(max_workers=physical_cpus) as executor:\n",
    "#     futures = [executor.submit(run_analysis, args=(stock_codes_ls, process_lock))\n",
    "#         for stock_codes_ls in chunked_list]\n",
    "#     for future in as_completed(futures):\n",
    "#         try:\n",
    "#             future.result() \n",
    "#         except Exception as e:\n",
    "#             print(\"Error in thread:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccd560fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validate_proxy(proxies, result_queue):\n",
    "#     \"\"\"验证代理有效性 [6]()\"\"\"\n",
    "#     test_url = \"http://icanhazip.com\"   # 测试网站 \n",
    "#     for proxy in proxies:\n",
    "#         # print(\"Testing proxy:\", proxy)\n",
    "#         try:\n",
    "#             start_time = time.time() \n",
    "#             resp = requests.get(test_url,  proxies=proxy, timeout=5)\n",
    "#             latency = int((time.time()  - start_time))  # 计算延迟 \n",
    "#             # print(resp.status_code, type(resp.status_code),resp.text,proxy)\n",
    "#             if resp.status_code  == 200:\n",
    "#                 result_queue.put((latency, proxy))\n",
    "#         except Exception:\n",
    "#             pass\n",
    "\n",
    "# proxies_map = []\n",
    "# response = requests.get('https://api.proxyscrape.com/v4/free-proxy-list/get?request=display_proxies&proxy_format=protocolipport&format=text',  timeout=30)\n",
    "# if response.status_code == 200:\n",
    "#     proxies = response.text.replace(\"socks4\",  \"https\")\n",
    "#     proxies_ls = [proxy for proxy in proxies.split('\\r\\n')  if proxy != \"\"]\n",
    "\n",
    "#     for url in proxies_ls:\n",
    "#         try:\n",
    "#             # 按 \"://\" 分割协议和地址（最多分割1次）\n",
    "#             protocol, _address = url.split('://',  1)\n",
    "#             if protocol == \"http\":\n",
    "#                 proxies_map.append({protocol: url})\n",
    "#         except ValueError:\n",
    "#             # 处理无效格式（如缺少 ://）\n",
    "#             print(f\"跳过无效URL: {url}\")\n",
    "#     print(proxies_map)\n",
    "# aspls = np.array_split(proxies_map, logical_cpus)\n",
    "# # 然后每个子数组是numpy数组，可以转成列表\n",
    "# chunked_list = [arr.tolist() for arr in aspls]\n",
    "\n",
    "# validate_proxies_queue = queue.Queue()\n",
    "# validate_proxies_ls = []\n",
    "\n",
    "# process_lock = multiprocessing.Lock()\n",
    "\n",
    "# with ThreadPoolExecutor(max_workers=logical_cpus) as executor:\n",
    "#     futures = [executor.submit(validate_proxy, proxies, validate_proxies_queue)\n",
    "#         for proxies in chunked_list]\n",
    "#     for future in as_completed(futures):\n",
    "#         try:\n",
    "#             future.result()\n",
    "#         except Exception as e:\n",
    "#             print(\"Error in got results thread:\", e)\n",
    "\n",
    "# while not validate_proxies_queue.empty():\n",
    "#     validate_proxies_ls.append(validate_proxies_queue.get())\n",
    "\n",
    "# validate_proxies_ls =sorted(validate_proxies_ls, key=lambda x: x[0])\n",
    "# for i in validate_proxies_ls:\n",
    "#     validate_proxies_queue.put(i[1])\n",
    "\n",
    "# print(validate_proxies_ls)\n",
    "# print(len(validate_proxies_ls))\n",
    "# print(validate_proxies_queue.empty())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76582855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stock_data_getter_with_proxies(stock_codes, formatted_start_day, formatted_today, validate_proxies_queue):\n",
    "#     res_ls = []\n",
    "#     if validate_proxies_queue.empty():\n",
    "#         return []\n",
    "#     proxy = validate_proxies_queue.get()\n",
    "#     i = 0\n",
    "#     while i < len(stock_codes):\n",
    "#         time.sleep(0.8) #avoid abandon from remote\n",
    "#         stock_code = stock_codes[i]\n",
    "#         i += 1\n",
    "#         stock_zh_a_hist_df = kline_daily.stock_zh_a_hist_with_proxy(symbol=stock_code, start_date=formatted_start_day, end_date=formatted_today, proxy={\"http\":proxy[\"http\"]})\n",
    "#         if stock_zh_a_hist_df is None:\n",
    "#             if validate_proxies_queue.empty():\n",
    "#                 print(\"proxy ran out\")\n",
    "#                 return []\n",
    "#             proxy = validate_proxies_queue.get()\n",
    "#             i -= 1\n",
    "#         elif stock_zh_a_hist_df.empty:\n",
    "#             print(\"wrong code:\",stock_code)\n",
    "#         else:\n",
    "#             res_ls.append((stock_code, stock_zh_a_hist_df))\n",
    "#     print(\"stock code:\",stock_codes[-1],\"data collection finished:\", time.time())\n",
    "#     return res_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0f4d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect_and_analyze_data([\"000001\",\"000002\"], log_phy_ratio, formatted_start_day, formatted_today, lock, run_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d038d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sd = ak.stock_zh_a_hist(symbol=\"000001\", period=\"daily\", start_date=formatted_start_day, end_date=formatted_today, adjust=\"\")\n",
    "# print(sd)\n",
    "# df_shanghai = ak.index_zh_a_hist( \n",
    "#     symbol=\"000001\",      # 上证指数代码（固定为000001）\n",
    "#     period=\"daily\",       # 数据周期：daily（日线）、weekly（周线）、monthly（月线）\n",
    "#     start_date=\"20200101\", # 起始日期（格式：YYYYMMDD）\n",
    "#     end_date=\"20250904\",   # 结束日期（默认为当前日期）\n",
    "# )\n",
    "\n",
    "# # 查看前5行数据 \n",
    "# print(df_shanghai.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18438774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_mainboard_stocks_ak():\n",
    "#     \"\"\"使用akshare获取主板股票列表\"\"\"\n",
    "#     # 获取所有上市公司的基本信息\n",
    "#     stock_info = ak.stock_info_a_code_name()\n",
    "    \n",
    "#     # 筛选主板股票\n",
    "#     mainboard_stocks = stock_info[stock_info['code'].str.startswith(('600', '601', '603', '605', '000', '002'))]\n",
    "    \n",
    "#     return mainboard_stocks\n",
    "\n",
    "# # 获取主板股票\n",
    "# mainboard_stocks_ak = get_mainboard_stocks_ak()\n",
    "# print(mainboard_stocks_ak.head())\n",
    "# mainboard_stocks_ak.to_csv('mainboard_stocks.csv', index=False, encoding='utf-8-sig')\n",
    "# def add_stock_prefix(code):\n",
    "#     code_str = str(code).zfill(6)  # 确保代码为6位字符串 \n",
    "#     if code_str.startswith('6'):    # 上证\n",
    "#         return 'sh' + code_str\n",
    "#     elif code_str.startswith(('0',  '3')):  # 深证\n",
    "#         return 'sz' + code_str \n",
    "#     return code_str  # 其他情况保留原格式 \n",
    "# mainboard_stocks_ak['code'] = mainboard_stocks_ak['code'].apply(add_stock_prefix)\n",
    "# mainboard_stocks_ak.to_csv('mainboard_stocks_with_prefix.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a612a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # date=\"20200331\"; choice of {\"XXXX0331\", \"XXXX0630\", \"XXXX0930\", \"XXXX1231\"}; 从 20081231 开始\n",
    "# stock_yjyg_em_df = ak.stock_yjyg_em(date=\"20250630\")\n",
    "# stock_yjyg_em_df_sorted_desc = stock_yjyg_em_df.sort_values(by=stock_yjyg_em_df.columns[6], ascending=False) #'业绩变动幅度'\n",
    "# # print(stock_yjyg_em_df_sorted_desc.head(10))\n",
    "# print(stock_yjyg_em_df_sorted_desc.iloc[:, [1,6]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "856e634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ProxyManager:\n",
    "#     \"\"\"代理IP管理器\"\"\"\n",
    "\n",
    "#     def __init__(self, proxy_api_url, max_retry=3):\n",
    "#         self.proxy_api_url = proxy_api_url\n",
    "#         self.max_retry = max_retry\n",
    "\n",
    "#     def get_valid_proxy(self):\n",
    "#         \"\"\"获取有效的代理IP\"\"\"\n",
    "#         for attempt in range(self.max_retry):\n",
    "#             try:\n",
    "#                 resp = requests.get(self.proxy_api_url, timeout=5)\n",
    "#                 proxy_json = resp.json()\n",
    "#                 proxy_data = proxy_json[\"data\"][0]\n",
    "#                 server = proxy_data[\"server\"]\n",
    "#                 ip, port = server.split(\":\")\n",
    "#                 proxy = {\"http\": f\"http://{ip}:{port}\", \"https\": f\"http://{ip}:{port}\"}\n",
    "\n",
    "#                 # 验证代理可用性\n",
    "#                 test_url = \"http://quote.eastmoney.com\"\n",
    "#                 test = requests.get(test_url, proxies=proxy, timeout=5)\n",
    "#                 if test.status_code == 200:\n",
    "#                     print(f\"代理可用: {ip}:{port}\")\n",
    "#                     return proxy\n",
    "#             except Exception as e:\n",
    "#                 print(f\"获取代理失败，第{attempt + 1}次尝试: {e}\")\n",
    "\n",
    "#         print(f\"未能获取有效代理\")\n",
    "#         return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
