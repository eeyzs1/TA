{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28ce91c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d79ebb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace \n",
    "from datetime import datetime, timedelta\n",
    "import akshare as ak\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "# import threading\n",
    "import threading\n",
    "import queue\n",
    "import psutil\n",
    "import time\n",
    "import talib\n",
    "from concurrent.futures  import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "# import kline_daily\n",
    "import requests\n",
    "# import cloudscraper\n",
    "import logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9653e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_zh_a_hist_tx(\n",
    "        symbol: str = \"sz000001\",\n",
    "        start_date: str = \"19000101\",\n",
    "        end_date: str = \"20500101\",\n",
    "        adjust: str = \"\",\n",
    "        timeout: float = None,\n",
    ") -> pd.DataFrame:\n",
    "    url = \"https://proxy.finance.qq.com/ifzqgtimg/appstock/app/newfqkline/get\"\n",
    "    big_df = pd.DataFrame()\n",
    "    params = {\n",
    "        \"_var\": f\"kline_day{adjust}{int(start_date[:4])}\",\n",
    "        \"param\": f\"{symbol},day,{start_date},{end_date},640,{adjust}\",\n",
    "        \"r\": str(random.random()),\n",
    "    }\n",
    "    r = requests.get(url, params=params, timeout=timeout)\n",
    "    data_text = r.text\n",
    "    data_json = ak.utils.demjson.decode(data_text[data_text.find(\"={\") + 1:])[\"data\"][\n",
    "        symbol\n",
    "    ]\n",
    "    if \"day\" in data_json.keys():\n",
    "        temp_df = pd.DataFrame(data_json[\"day\"])\n",
    "    elif \"hfqday\" in data_json.keys():\n",
    "        temp_df = pd.DataFrame(data_json[\"hfqday\"])\n",
    "    else:\n",
    "        temp_df = pd.DataFrame(data_json[\"qfqday\"])\n",
    "    big_df = pd.concat([big_df, temp_df], ignore_index=True)\n",
    "    \n",
    "    big_df = big_df.iloc[:, [0,1,2,3,4,5,7]]\n",
    "    big_df.columns = [\"date\", \"open\", \"close\", \"high\", \"low\", \"volume\",\"turnover_rate\"]\n",
    "    big_df[\"date\"] = pd.to_datetime(big_df[\"date\"], errors=\"coerce\").dt.date\n",
    "    big_df[\"open\"] = pd.to_numeric(big_df[\"open\"], errors=\"coerce\")\n",
    "    big_df[\"close\"] = pd.to_numeric(big_df[\"close\"], errors=\"coerce\")\n",
    "    big_df[\"high\"] = pd.to_numeric(big_df[\"high\"], errors=\"coerce\")\n",
    "    big_df[\"low\"] = pd.to_numeric(big_df[\"low\"], errors=\"coerce\")\n",
    "    big_df[\"volume\"] = pd.to_numeric(big_df[\"volume\"], errors=\"coerce\")\n",
    "    big_df[\"turnover_rate\"] = pd.to_numeric(big_df[\"turnover_rate\"], errors=\"coerce\")\n",
    "    big_df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    big_df.index = pd.to_datetime(big_df[\"date\"])\n",
    "    big_df = big_df[start_date:end_date]\n",
    "    big_df.reset_index(inplace=True, drop=True)\n",
    "    return big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a6dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置 root logger：记录 DEBUG 及以上到 all.log \n",
    "logging.basicConfig( \n",
    "    filename='all.log', \n",
    "    filemode='a',\n",
    "    level=logging.DEBUG,\n",
    "    encoding='utf-8',\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    " \n",
    "# 创建 error logger\n",
    "error_logger = logging.getLogger('error_logger') \n",
    "error_logger.setLevel(logging.ERROR)   # 设置 error_logger 只处理 ERROR 及以上级别 \n",
    " \n",
    "# 创建 error.log  的 handler\n",
    "error_handler = logging.FileHandler('error.log',  encoding='utf-8') \n",
    "error_handler.setLevel(logging.ERROR) \n",
    " \n",
    "# 设置 error 日志格式\n",
    "error_formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "error_handler.setFormatter(error_formatter) \n",
    " \n",
    "# 添加 handler 到 error_logger \n",
    "error_logger.addHandler(error_handler) \n",
    " \n",
    "# 防止日志重复传播到 root logger（避免 error 日志出现在 all.log  中两次）\n",
    "error_logger.propagate  = False\n",
    " \n",
    "# 测试日志\n",
    "logging.debug(' 这是 root logger 的 DEBUG 日志，写入 all.log') \n",
    "logging.info(' 这是 root logger 的 INFO 日志，写入 all.log') \n",
    "logging.critical(' 这是 root logger 的 Critical 日志，写入 all.log') \n",
    "error_logger.error(' 这是一个 ERROR 日志，写入 error.log  和 all.log （除非 propagate=False）')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "135e595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.error(\"dwdw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3b0d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_len = len(df)\n",
    "physical_cpus = psutil.cpu_count(logical=False)\n",
    "logical_cpus = psutil.cpu_count(logical=True)\n",
    "\n",
    "log_phy_ratio = int(logical_cpus/physical_cpus)\n",
    "# phy_cpu_length = int(total_len/physical_cpus)\n",
    "args = SimpleNamespace(\n",
    "    datedelta = 50,\n",
    "    start_epochs = 8\n",
    "    )\n",
    "today = datetime.now() - timedelta(days=1)\n",
    "start_day = today - timedelta(days=args.datedelta)\n",
    "# test_day = today - timedelta(days=1)\n",
    "\n",
    "# 格式化日期为YYYYMMDD格式\n",
    "# formatted_today = today.strftime('%Y%m%d')\n",
    "# formatted_test_day = test_day.strftime('%Y%m%d')\n",
    "# formatted_start_day = start_day.strftime('%Y%m%d')\n",
    "\n",
    "# 格式化日期为YYYY-MM-DD格式\n",
    "formatted_today = today.strftime('%Y-%m-%d')\n",
    "# formatted_test_day = test_day.strftime('%Y-%m-%d')\n",
    "formatted_start_day = start_day.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fcc91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('today_suggestions.txt', 'w', encoding='utf-8') as today_suggestions,open('history_suggestions.txt', 'a', encoding='utf-8') as history_suggestions:\n",
    "    today_suggestions.write(formatted_today + \"!!!!!!!!~~~~~~~~~~~~~~\\n\")\n",
    "    history_suggestions.write(formatted_today + \"!!!!!!!!!!!~~~~~~~~~~~~\\n\")\n",
    "# df = pd.read_csv('data.csv',  dtype={0: str})\n",
    "df = pd.read_csv('mainboard_stocks_with_prefix.csv', dtype={'code': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10e31cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sz000001</td>\n",
       "      <td>平安银行</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sz000002</td>\n",
       "      <td>万  科Ａ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sz000004</td>\n",
       "      <td>*ST国华</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sz000006</td>\n",
       "      <td>深振业Ａ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sz000007</td>\n",
       "      <td>全新好</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code   name\n",
       "0  sz000001   平安银行\n",
       "1  sz000002  万  科Ａ\n",
       "2  sz000004  *ST国华\n",
       "3  sz000006   深振业Ａ\n",
       "4  sz000007    全新好"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_codes = list(set(df['code']))\n",
    "print(len(df) == len(stock_codes))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe2b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_data_getter(stock_codes, formatted_start_day, formatted_today):\n",
    "    res_ls = []\n",
    "    for stock_code in stock_codes:\n",
    "        # time.sleep(0.8) #avoid abandon from remote\n",
    "        try:\n",
    "            stock_zh_a_hist_df = stock_zh_a_hist_tx(symbol=stock_code, start_date=formatted_start_day, end_date=formatted_today)\n",
    "            if stock_zh_a_hist_df.empty:\n",
    "                print(\"wrong code:\",stock_code)\n",
    "            else:\n",
    "                res_ls.append((stock_code, stock_zh_a_hist_df))\n",
    "        except Exception as e:\n",
    "            print(\"exception:\",e)\n",
    "            logging.error(e)\n",
    "    print(\"stock code:\",stock_codes[-1],\"data collection finished:\", time.time())\n",
    "    return res_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcdb32ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock code: sh600127 data collection finished: 1758155840.8170342\n",
      "stock code: sz002028 data collection finished: 1758155842.5265985\n",
      "stock code: sh600848 data collection finished: 1758155842.69996\n",
      "stock code: sh603406 data collection finished: 1758155843.3747275\n",
      "stock code: sh603016 data collection finished: 1758155843.563243\n",
      "stock code: sh600809 data collection finished: 1758155843.772987\n",
      "stock code: sz002613 data collection finished: 1758155844.4541495\n",
      "stock code: sz002860 data collection finished: 1758155844.602793\n",
      "stock code: sz002915 data collection finished: 1758155844.9929018\n",
      "stock code: sh600109 data collection finished: 1758155844.9929018\n",
      "stock code: sh603339 data collection finished: 1758155844.9963453\n",
      "stock code: sh600015 data collection finished: 1758155845.871683\n",
      "stock code: sh603618 data collection finished: 1758155845.9314978\n",
      "stock code: sh603612 data collection finished: 1758155846.2028115\n",
      "stock code: sz002602 data collection finished: 1758155846.2209134\n",
      "stock code: sh600676 data collection finished: 1758155846.3693147\n",
      "stock code: sh601939 data collection finished: 1758155846.7611487\n",
      "stock code: sz000963 data collection finished: 1758155847.1500711\n",
      "stock code: sh600352 data collection finished: 1758155847.1778922\n",
      "stock code: sh603528 data collection finished: 1758155847.1854165\n",
      "stock code: sh600189 data collection finished: 1758155847.2858102\n",
      "stock code: sz002311 data collection finished: 1758155847.2877192\n",
      "stock code: sz002291 data collection finished: 1758155847.2877192\n",
      "stock code: sz002959 data collection finished: 1758155847.2961087\n",
      "stock code: sz000925 data collection finished: 1758155847.2976835\n",
      "stock code: sh603156 data collection finished: 1758155847.2987392\n",
      "stock code: sh603809 data collection finished: 1758155847.2987392\n",
      "stock code: sh600650 data collection finished: 1758155847.5560534\n",
      "stock code: sz000718 data collection finished: 1758155847.6974623\n",
      "stock code: sz000070 data collection finished: 1758155847.7265522\n",
      "stock code: sz002195 data collection finished: 1758155847.7306452\n",
      "stock code: sz000850 data collection finished: 1758155847.7319033\n"
     ]
    }
   ],
   "source": [
    "aspls = np.array_split(stock_codes, logical_cpus)\n",
    "# 然后每个子数组是numpy数组，可以转成列表\n",
    "chunked_list = [arr.tolist() for arr in aspls]\n",
    "\n",
    "process_lock = multiprocessing.Lock()\n",
    "\n",
    "stock_data = []\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=logical_cpus) as executor:\n",
    "    futures = [executor.submit(stock_data_getter, stock_codes_ls, formatted_start_day, formatted_today)\n",
    "        for stock_codes_ls in chunked_list]\n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            result = future.result() \n",
    "            stock_data += result\n",
    "        except Exception as e:\n",
    "            print(\"Error in got results thread:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c20bd998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3032 3032\n"
     ]
    }
   ],
   "source": [
    "print(len(stock_data),len(stock_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bc7036f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date   open  close   high    low    volume  turnover_rate\n",
      "0   2025-07-29  15.75  15.50  15.82  15.38  100630.0           5.26\n",
      "1   2025-07-30  15.60  15.34  15.60  15.20   64681.0           3.38\n",
      "2   2025-07-31  15.34  15.34  15.60  15.23   76545.0           4.00\n",
      "3   2025-08-01  15.34  15.43  15.50  15.25   44971.0           2.35\n",
      "4   2025-08-04  15.43  15.81  15.82  15.30   81195.0           4.25\n",
      "5   2025-08-05  16.00  15.76  16.00  15.68   57096.0           2.99\n",
      "6   2025-08-06  15.76  15.87  15.93  15.68   53918.0           2.82\n",
      "7   2025-08-07  15.87  16.13  16.30  15.73   83376.0           4.36\n",
      "8   2025-08-08  16.12  16.68  17.03  15.74  131977.0           6.91\n",
      "9   2025-08-11  16.68  16.57  16.75  16.38   85022.0           4.45\n",
      "10  2025-08-12  16.53  16.57  16.68  16.39   53980.0           2.82\n",
      "11  2025-08-13  16.49  16.42  16.69  16.31   59826.0           3.13\n",
      "12  2025-08-14  16.38  15.87  16.48  15.80   80110.0           4.19\n",
      "13  2025-08-15  15.96  16.11  16.14  15.88   56636.0           2.96\n",
      "14  2025-08-18  16.17  15.98  16.25  15.89   69662.0           3.64\n",
      "15  2025-08-19  15.98  16.19  16.24  15.91   52128.0           2.73\n",
      "16  2025-08-20  16.29  17.15  17.81  16.28  220244.0          11.52\n",
      "17  2025-08-21  17.11  16.74  17.26  16.68  113809.0           5.95\n",
      "18  2025-08-22  16.72  16.65  17.00  16.57   71426.0           3.74\n",
      "19  2025-08-25  16.69  16.62  16.75  16.47   57100.0           2.99\n",
      "20  2025-08-26  16.52  16.69  16.94  16.52   71060.0           3.72\n",
      "21  2025-08-27  16.81  15.90  16.81  15.88   82717.0           4.33\n",
      "22  2025-08-28  15.90  15.73  16.20  15.22   87825.0           4.59\n",
      "23  2025-08-29  15.66  15.60  15.77  15.47   46492.0           2.43\n",
      "24  2025-09-01  15.61  15.82  15.96  15.56   35343.0           1.85\n",
      "25  2025-09-02  15.86  15.40  15.94  15.15   58902.0           3.08\n",
      "26  2025-09-03  15.43  15.05  15.56  14.95   37221.0           1.95\n",
      "27  2025-09-04  15.08  15.45  15.57  15.05   49405.0           2.58\n",
      "28  2025-09-05  15.67  16.35  16.41  15.40   89905.0           4.70\n",
      "29  2025-09-08  16.34  16.63  16.98  16.34   88631.0           4.64\n",
      "30  2025-09-09  16.63  16.42  16.63  16.23   51188.0           2.68\n",
      "31  2025-09-10  16.31  16.22  16.60  16.06   34497.0           1.80\n",
      "32  2025-09-11  16.22  16.22  16.25  15.99   36055.0           1.89\n",
      "33  2025-09-12  16.24  16.06  16.37  16.00   32367.0           1.69\n",
      "34  2025-09-15  16.07  16.36  16.61  16.01   58915.0           3.08\n",
      "35  2025-09-16  16.31  16.54  16.70  15.98   72160.0           3.78\n",
      "36  2025-09-17  16.67  16.50  17.17  16.48   98634.0           5.16\n"
     ]
    }
   ],
   "source": [
    "print(stock_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd604b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdaspls = np.array_split(np.array(stock_data,  dtype=object), physical_cpus)\n",
    "# sd_chunked_list = [arr.tolist() for arr in sdaspls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dfd9ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_code: sz002174 result: 超跌反转+资金异动型 \n",
      " \n",
      "wrong count 0\n"
     ]
    }
   ],
   "source": [
    "def check_parameter(stock_codes_ls):\n",
    "    count = 0\n",
    "    for stock_code, stock_zh_df in stock_codes_ls:\n",
    "        open = stock_zh_df[\"open\"]\n",
    "        close = stock_zh_df[\"close\"]\n",
    "        high = stock_zh_df[\"high\"]\n",
    "        low = stock_zh_df[\"low\"]\n",
    "        volume = stock_zh_df[\"volume\"]\n",
    "        turnover = stock_zh_df[\"turnover_rate\"]\n",
    "\n",
    "        ma5 = talib.EMA(close, timeperiod=5)\n",
    "        ma10 = talib.EMA(close, timeperiod=10)\n",
    "        vol_ma5 = talib.EMA(volume, timeperiod=5)\n",
    "        atr = talib.NATR(high, low, close, timeperiod=8) #波动\n",
    "        atr_ma = talib.EMA(atr, timeperiod=5)\n",
    "        macd, macdsignal, macdhist = talib.MACD(close, fastperiod=7, slowperiod=18, signalperiod=6)\n",
    "\n",
    "        rsi = talib.RSI(close, timeperiod=14)  # RSI相对强弱指标\n",
    "        cci = talib.CCI(high, low, close, timeperiod=20)  # 顺势指标\n",
    "        # money_flow = (2*close - low - high) / (high - low) * volume  # 简易资金流\n",
    "        money_flow = talib.MFI(high, low, close, volume, timeperiod=9)\n",
    "        # money_flow_max= money_flow.shift(3).rolling(4).max().iloc[-1]\n",
    "        # turnover_mean= money_flow.shift(1).rolling(5).mean().iloc[-1]\n",
    "        today_candlestick = abs(close.iloc[-3] - open.iloc[-3])\n",
    "        yesterday_candlestick = abs(close.iloc[-4] - open.iloc[-4])\n",
    "        \n",
    "        if (close.iloc[-3] > ma5.iloc[-3] and (ma5.iloc[3] > ma10.iloc[-3]  or (ma5.iloc[-3] > ma5.iloc[-4] > ma5.iloc[-5]))) and \\\n",
    "            rsi.iloc[-3] < 60 and atr.iloc[-3]  > atr_ma.iloc[-3] and open.iloc[-3]  < close.iloc[-3]  * 1.03 and \\\n",
    "                volume.iloc[-3] >= vol_ma5.iloc[-3] * 1.5 and turnover.iloc[-3] > 3 and \\\n",
    "                (macd.iloc[-3] > macdsignal.iloc[-3] and macd.iloc[-4] < macdsignal.iloc[-4] and macdhist.iloc[-3] > abs(macdhist.iloc[-4])):\n",
    "            if close.iloc[-1] > close.iloc[-2]:\n",
    "                print(f\"\"\"stock_code: {stock_code} result: 趋势启动+量价齐升型 \\n \"\"\")\n",
    "            else:\n",
    "                print(f\"\"\"XXXXXXstock_code: {stock_code} wrong result: 趋势启动+量价齐升型 \\n \"\"\")\n",
    "                count += 1\n",
    "        elif (rsi.iloc[-3] < 35) and (cci.iloc[-3] < -100) and \\\n",
    "            today_candlestick > 0.5 * yesterday_candlestick and turnover.iloc[-1] > 3 and \\\n",
    "            money_flow.iloc[-3] > money_flow.iloc[-4]:\n",
    "            if close.iloc[-1] > close.iloc[-2]:\n",
    "                print(f\"\"\"stock_code: {stock_code} result: 超跌反转+资金异动型 \\n \"\"\")\n",
    "            else:\n",
    "                print(f\"\"\"XXXXXXstock_code: {stock_code} wrong result: 超跌反转+资金异动型 \\n \"\"\")\n",
    "                count += 1\n",
    "    print(\"wrong count\", count)\n",
    "\n",
    "check_parameter(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "007a97d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ProcessPoolExecutor(max_workers=physical_cpus) as executor:\n",
    "#     futures = [executor.submit(check_parameter, sd_ls)\n",
    "#         for sd_ls in sd_chunked_list]\n",
    "#     for future in as_completed(futures):\n",
    "#         try:\n",
    "#             future.result() \n",
    "#         except Exception as e:\n",
    "#             print(\"Error in process:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a8447d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_code: sz002803 result: 趋势启动+量价齐升型 \n",
      " \n",
      "stock_code: sh600390 result: 趋势启动+量价齐升型 \n",
      " \n",
      "stock_code: sz000151 result: 趋势启动+量价齐升型 \n",
      " \n",
      "stock_code: sz002174 result: 超跌反转+资金异动型 \n",
      " \n",
      "stock_code: sz002453 result: 趋势启动+量价齐升型 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "def run_analysis(stock_codes_ls):\n",
    "    res_ls = []\n",
    "    for stock_code, stock_zh_df in stock_codes_ls:\n",
    "        open = stock_zh_df[\"open\"]\n",
    "        close = stock_zh_df[\"close\"]\n",
    "        high = stock_zh_df[\"high\"]\n",
    "        low = stock_zh_df[\"low\"]\n",
    "        volume = stock_zh_df[\"volume\"]\n",
    "        turnover = stock_zh_df[\"turnover_rate\"]\n",
    "\n",
    "        ma5 = talib.EMA(close, timeperiod=5)\n",
    "        ma10 = talib.EMA(close, timeperiod=10)\n",
    "        vol_ma5 = talib.EMA(volume, timeperiod=5)\n",
    "        atr = talib.NATR(high, low, close, timeperiod=8)\n",
    "        atr_ma = talib.EMA(atr, timeperiod=5)\n",
    "        macd, macdsignal, macdhist = talib.MACD(close, fastperiod=7, slowperiod=18, signalperiod=6)#快速EMA：6~8，慢速EMA：15~20，信号线：5~7\n",
    "\n",
    "        rsi = talib.RSI(close, timeperiod=14)  # RSI相对强弱指标\n",
    "        cci = talib.CCI(high, low, close, timeperiod=20)  # 顺势指标\n",
    "        # money_flow = (2*close - low - high) / (high - low) * volume  # 简易资金流\n",
    "        money_flow = talib.MFI(high, low, close, volume, timeperiod=9)\n",
    "        # money_flow_max= money_flow.shift(1).rolling(4).max().iloc[-1]\n",
    "        # turnover_mean= money_flow.shift(1).rolling(5).mean().iloc[-1]\n",
    "        today_candlestick = abs(close.iloc[-1] - open.iloc[-1])\n",
    "        yesterday_candlestick = abs(close.iloc[-2] - open.iloc[-2])\n",
    "\n",
    "        if close.iloc[-1] > ma5.iloc[-1] and (ma5.iloc[1] > ma10.iloc[-1] or (ma5.iloc[-1] > ma5.iloc[-2] > ma5.iloc[-3])) and \\\n",
    "                rsi.iloc[-1] < 60 and atr.iloc[-1]  > atr_ma.iloc[-1] and open.iloc[-1]  < close.iloc[-1]  * 1.03 and \\\n",
    "                volume.iloc[-1] >= vol_ma5.iloc[-1] * 1.5 and turnover.iloc[-1] > 3 and \\\n",
    "                macd.iloc[-1] > macdsignal.iloc[-1] and macd.iloc[-2] < macdsignal.iloc[-2] and macdhist.iloc[-1] > abs(macdhist.iloc[-2]):\n",
    "            res_ls.append(f\"\"\"stock_code: {stock_code} result: 趋势启动+量价齐升型 \\n \"\"\")\n",
    "        elif (rsi.iloc[-1] < 35) and (cci.iloc[-1] < -100) and \\\n",
    "            today_candlestick > 0.5 * yesterday_candlestick and turnover.iloc[-1] > 3 and \\\n",
    "            money_flow.iloc[-1] > money_flow.iloc[-2]:\n",
    "            res_ls.append(f\"\"\"stock_code: {stock_code} result: 超跌反转+资金异动型 \\n \"\"\")\n",
    "\n",
    "    for result in res_ls:\n",
    "        print(result)\n",
    "    # with open('today_suggestions.txt', 'a', encoding='utf-8') as today_suggestions,open('history_suggestions.txt', 'a', encoding='utf-8') as history_suggestions:\n",
    "    #     for result in res_ls:\n",
    "    #         today_suggestions.write(result)\n",
    "    #         history_suggestions.write(result)\n",
    "\n",
    "\n",
    "run_analysis(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0d37891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ProcessPoolExecutor(max_workers=physical_cpus) as executor:\n",
    "#     futures = [executor.submit(run_analysis, args=(stock_codes_ls, process_lock))\n",
    "#         for stock_codes_ls in chunked_list]\n",
    "#     for future in as_completed(futures):\n",
    "#         try:\n",
    "#             future.result() \n",
    "#         except Exception as e:\n",
    "#             print(\"Error in thread:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccd560fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validate_proxy(proxies, result_queue):\n",
    "#     \"\"\"验证代理有效性 [6]()\"\"\"\n",
    "#     test_url = \"http://icanhazip.com\"   # 测试网站 \n",
    "#     for proxy in proxies:\n",
    "#         # print(\"Testing proxy:\", proxy)\n",
    "#         try:\n",
    "#             start_time = time.time() \n",
    "#             resp = requests.get(test_url,  proxies=proxy, timeout=5)\n",
    "#             latency = int((time.time()  - start_time))  # 计算延迟 \n",
    "#             # print(resp.status_code, type(resp.status_code),resp.text,proxy)\n",
    "#             if resp.status_code  == 200:\n",
    "#                 result_queue.put((latency, proxy))\n",
    "#         except Exception:\n",
    "#             pass\n",
    "\n",
    "# proxies_map = []\n",
    "# response = requests.get('https://api.proxyscrape.com/v4/free-proxy-list/get?request=display_proxies&proxy_format=protocolipport&format=text',  timeout=30)\n",
    "# if response.status_code == 200:\n",
    "#     proxies = response.text.replace(\"socks4\",  \"https\")\n",
    "#     proxies_ls = [proxy for proxy in proxies.split('\\r\\n')  if proxy != \"\"]\n",
    "\n",
    "#     for url in proxies_ls:\n",
    "#         try:\n",
    "#             # 按 \"://\" 分割协议和地址（最多分割1次）\n",
    "#             protocol, _address = url.split('://',  1)\n",
    "#             if protocol == \"http\":\n",
    "#                 proxies_map.append({protocol: url})\n",
    "#         except ValueError:\n",
    "#             # 处理无效格式（如缺少 ://）\n",
    "#             print(f\"跳过无效URL: {url}\")\n",
    "#     print(proxies_map)\n",
    "# aspls = np.array_split(proxies_map, logical_cpus)\n",
    "# # 然后每个子数组是numpy数组，可以转成列表\n",
    "# chunked_list = [arr.tolist() for arr in aspls]\n",
    "\n",
    "# validate_proxies_queue = queue.Queue()\n",
    "# validate_proxies_ls = []\n",
    "\n",
    "# process_lock = multiprocessing.Lock()\n",
    "\n",
    "# with ThreadPoolExecutor(max_workers=logical_cpus) as executor:\n",
    "#     futures = [executor.submit(validate_proxy, proxies, validate_proxies_queue)\n",
    "#         for proxies in chunked_list]\n",
    "#     for future in as_completed(futures):\n",
    "#         try:\n",
    "#             future.result()\n",
    "#         except Exception as e:\n",
    "#             print(\"Error in got results thread:\", e)\n",
    "\n",
    "# while not validate_proxies_queue.empty():\n",
    "#     validate_proxies_ls.append(validate_proxies_queue.get())\n",
    "\n",
    "# validate_proxies_ls =sorted(validate_proxies_ls, key=lambda x: x[0])\n",
    "# for i in validate_proxies_ls:\n",
    "#     validate_proxies_queue.put(i[1])\n",
    "\n",
    "# print(validate_proxies_ls)\n",
    "# print(len(validate_proxies_ls))\n",
    "# print(validate_proxies_queue.empty())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76582855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stock_data_getter_with_proxies(stock_codes, formatted_start_day, formatted_today, validate_proxies_queue):\n",
    "#     res_ls = []\n",
    "#     if validate_proxies_queue.empty():\n",
    "#         return []\n",
    "#     proxy = validate_proxies_queue.get()\n",
    "#     i = 0\n",
    "#     while i < len(stock_codes):\n",
    "#         time.sleep(0.8) #avoid abandon from remote\n",
    "#         stock_code = stock_codes[i]\n",
    "#         i += 1\n",
    "#         stock_zh_a_hist_df = kline_daily.stock_zh_a_hist_with_proxy(symbol=stock_code, start_date=formatted_start_day, end_date=formatted_today, proxy={\"http\":proxy[\"http\"]})\n",
    "#         if stock_zh_a_hist_df is None:\n",
    "#             if validate_proxies_queue.empty():\n",
    "#                 print(\"proxy ran out\")\n",
    "#                 return []\n",
    "#             proxy = validate_proxies_queue.get()\n",
    "#             i -= 1\n",
    "#         elif stock_zh_a_hist_df.empty:\n",
    "#             print(\"wrong code:\",stock_code)\n",
    "#         else:\n",
    "#             res_ls.append((stock_code, stock_zh_a_hist_df))\n",
    "#     print(\"stock code:\",stock_codes[-1],\"data collection finished:\", time.time())\n",
    "#     return res_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0f4d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect_and_analyze_data([\"000001\",\"000002\"], log_phy_ratio, formatted_start_day, formatted_today, lock, run_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d038d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sd = ak.stock_zh_a_hist(symbol=\"000001\", period=\"daily\", start_date=formatted_start_day, end_date=formatted_today, adjust=\"\")\n",
    "# print(sd)\n",
    "# df_shanghai = ak.index_zh_a_hist( \n",
    "#     symbol=\"000001\",      # 上证指数代码（固定为000001）\n",
    "#     period=\"daily\",       # 数据周期：daily（日线）、weekly（周线）、monthly（月线）\n",
    "#     start_date=\"20200101\", # 起始日期（格式：YYYYMMDD）\n",
    "#     end_date=\"20250904\",   # 结束日期（默认为当前日期）\n",
    "# )\n",
    "\n",
    "# # 查看前5行数据 \n",
    "# print(df_shanghai.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18438774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_mainboard_stocks_ak():\n",
    "#     \"\"\"使用akshare获取主板股票列表\"\"\"\n",
    "#     # 获取所有上市公司的基本信息\n",
    "#     stock_info = ak.stock_info_a_code_name()\n",
    "    \n",
    "#     # 筛选主板股票\n",
    "#     mainboard_stocks = stock_info[stock_info['code'].str.startswith(('600', '601', '603', '605', '000', '002'))]\n",
    "    \n",
    "#     return mainboard_stocks\n",
    "\n",
    "# # 获取主板股票\n",
    "# mainboard_stocks_ak = get_mainboard_stocks_ak()\n",
    "# print(mainboard_stocks_ak.head())\n",
    "# mainboard_stocks_ak.to_csv('mainboard_stocks.csv', index=False, encoding='utf-8-sig')\n",
    "# def add_stock_prefix(code):\n",
    "#     code_str = str(code).zfill(6)  # 确保代码为6位字符串 \n",
    "#     if code_str.startswith('6'):    # 上证\n",
    "#         return 'sh' + code_str\n",
    "#     elif code_str.startswith(('0',  '3')):  # 深证\n",
    "#         return 'sz' + code_str \n",
    "#     return code_str  # 其他情况保留原格式 \n",
    "# mainboard_stocks_ak['code'] = mainboard_stocks_ak['code'].apply(add_stock_prefix)\n",
    "# mainboard_stocks_ak.to_csv('mainboard_stocks_with_prefix.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a612a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # date=\"20200331\"; choice of {\"XXXX0331\", \"XXXX0630\", \"XXXX0930\", \"XXXX1231\"}; 从 20081231 开始\n",
    "# stock_yjyg_em_df = ak.stock_yjyg_em(date=\"20250630\")\n",
    "# stock_yjyg_em_df_sorted_desc = stock_yjyg_em_df.sort_values(by=stock_yjyg_em_df.columns[6], ascending=False) #'业绩变动幅度'\n",
    "# # print(stock_yjyg_em_df_sorted_desc.head(10))\n",
    "# print(stock_yjyg_em_df_sorted_desc.iloc[:, [1,6]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "856e634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ProxyManager:\n",
    "#     \"\"\"代理IP管理器\"\"\"\n",
    "\n",
    "#     def __init__(self, proxy_api_url, max_retry=3):\n",
    "#         self.proxy_api_url = proxy_api_url\n",
    "#         self.max_retry = max_retry\n",
    "\n",
    "#     def get_valid_proxy(self):\n",
    "#         \"\"\"获取有效的代理IP\"\"\"\n",
    "#         for attempt in range(self.max_retry):\n",
    "#             try:\n",
    "#                 resp = requests.get(self.proxy_api_url, timeout=5)\n",
    "#                 proxy_json = resp.json()\n",
    "#                 proxy_data = proxy_json[\"data\"][0]\n",
    "#                 server = proxy_data[\"server\"]\n",
    "#                 ip, port = server.split(\":\")\n",
    "#                 proxy = {\"http\": f\"http://{ip}:{port}\", \"https\": f\"http://{ip}:{port}\"}\n",
    "\n",
    "#                 # 验证代理可用性\n",
    "#                 test_url = \"http://quote.eastmoney.com\"\n",
    "#                 test = requests.get(test_url, proxies=proxy, timeout=5)\n",
    "#                 if test.status_code == 200:\n",
    "#                     print(f\"代理可用: {ip}:{port}\")\n",
    "#                     return proxy\n",
    "#             except Exception as e:\n",
    "#                 print(f\"获取代理失败，第{attempt + 1}次尝试: {e}\")\n",
    "\n",
    "#         print(f\"未能获取有效代理\")\n",
    "#         return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
