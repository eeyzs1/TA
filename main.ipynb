{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28ce91c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d79ebb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace \n",
    "from datetime import datetime, timedelta\n",
    "import akshare as ak\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "# import threading\n",
    "import threading\n",
    "import queue\n",
    "import psutil\n",
    "import time\n",
    "import talib\n",
    "from concurrent.futures  import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "# import kline_daily\n",
    "import requests\n",
    "# import cloudscraper\n",
    "import logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9653e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_zh_a_hist_tx(\n",
    "        symbol: str = \"sz000001\",\n",
    "        start_date: str = \"19000101\",\n",
    "        end_date: str = \"20500101\",\n",
    "        adjust: str = \"\",\n",
    "        timeout: float = None,\n",
    ") -> pd.DataFrame:\n",
    "    url = \"https://proxy.finance.qq.com/ifzqgtimg/appstock/app/newfqkline/get\"\n",
    "    big_df = pd.DataFrame()\n",
    "    params = {\n",
    "        \"_var\": f\"kline_day{adjust}{int(start_date[:4])}\",\n",
    "        \"param\": f\"{symbol},day,{start_date},{end_date},640,{adjust}\",\n",
    "        \"r\": str(random.random()),\n",
    "    }\n",
    "    r = requests.get(url, params=params, timeout=timeout)\n",
    "    data_text = r.text\n",
    "    data_json = ak.utils.demjson.decode(data_text[data_text.find(\"={\") + 1:])[\"data\"][\n",
    "        symbol\n",
    "    ]\n",
    "    if \"day\" in data_json.keys():\n",
    "        temp_df = pd.DataFrame(data_json[\"day\"])\n",
    "    elif \"hfqday\" in data_json.keys():\n",
    "        temp_df = pd.DataFrame(data_json[\"hfqday\"])\n",
    "    else:\n",
    "        temp_df = pd.DataFrame(data_json[\"qfqday\"])\n",
    "    big_df = pd.concat([big_df, temp_df], ignore_index=True)\n",
    "    \n",
    "    big_df = big_df.iloc[:, [0,1,2,3,4,5,7]]\n",
    "    big_df.columns = [\"date\", \"open\", \"close\", \"high\", \"low\", \"volume\",\"turnover_rate\"]\n",
    "    big_df[\"date\"] = pd.to_datetime(big_df[\"date\"], errors=\"coerce\").dt.date\n",
    "    big_df[\"open\"] = pd.to_numeric(big_df[\"open\"], errors=\"coerce\")\n",
    "    big_df[\"close\"] = pd.to_numeric(big_df[\"close\"], errors=\"coerce\")\n",
    "    big_df[\"high\"] = pd.to_numeric(big_df[\"high\"], errors=\"coerce\")\n",
    "    big_df[\"low\"] = pd.to_numeric(big_df[\"low\"], errors=\"coerce\")\n",
    "    big_df[\"volume\"] = pd.to_numeric(big_df[\"volume\"], errors=\"coerce\")\n",
    "    big_df[\"turnover_rate\"] = pd.to_numeric(big_df[\"turnover_rate\"], errors=\"coerce\")\n",
    "    big_df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    big_df.index = pd.to_datetime(big_df[\"date\"])\n",
    "    big_df = big_df[start_date:end_date]\n",
    "    big_df.reset_index(inplace=True, drop=True)\n",
    "    return big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a6dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置 root logger：记录 DEBUG 及以上到 all.log \n",
    "logging.basicConfig( \n",
    "    filename='all.log', \n",
    "    filemode='a',\n",
    "    level=logging.DEBUG,\n",
    "    encoding='utf-8',\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    " \n",
    "# 创建 error logger\n",
    "error_logger = logging.getLogger('error_logger') \n",
    "error_logger.setLevel(logging.ERROR)   # 设置 error_logger 只处理 ERROR 及以上级别 \n",
    " \n",
    "# 创建 error.log  的 handler\n",
    "error_handler = logging.FileHandler('error.log',  encoding='utf-8') \n",
    "error_handler.setLevel(logging.ERROR) \n",
    " \n",
    "# 设置 error 日志格式\n",
    "error_formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "error_handler.setFormatter(error_formatter) \n",
    " \n",
    "# 添加 handler 到 error_logger \n",
    "error_logger.addHandler(error_handler) \n",
    " \n",
    "# 防止日志重复传播到 root logger（避免 error 日志出现在 all.log  中两次）\n",
    "error_logger.propagate  = False\n",
    " \n",
    "# 测试日志\n",
    "logging.debug(' 这是 root logger 的 DEBUG 日志，写入 all.log') \n",
    "logging.info(' 这是 root logger 的 INFO 日志，写入 all.log') \n",
    "logging.critical(' 这是 root logger 的 Critical 日志，写入 all.log') \n",
    "error_logger.error(' 这是一个 ERROR 日志，写入 error.log  和 all.log （除非 propagate=False）')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "135e595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.error(\"dwdw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3b0d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_len = len(df)\n",
    "physical_cpus = psutil.cpu_count(logical=False)\n",
    "logical_cpus = psutil.cpu_count(logical=True)\n",
    "\n",
    "log_phy_ratio = int(logical_cpus/physical_cpus)\n",
    "# phy_cpu_length = int(total_len/physical_cpus)\n",
    "args = SimpleNamespace(\n",
    "    datedelta = 50,\n",
    "    start_epochs = 8\n",
    "    )\n",
    "today = datetime.now() - timedelta(days=1)\n",
    "start_day = today - timedelta(days=args.datedelta)\n",
    "# test_day = today - timedelta(days=1)\n",
    "\n",
    "# 格式化日期为YYYYMMDD格式\n",
    "# formatted_today = today.strftime('%Y%m%d')\n",
    "# formatted_test_day = test_day.strftime('%Y%m%d')\n",
    "# formatted_start_day = start_day.strftime('%Y%m%d')\n",
    "\n",
    "# 格式化日期为YYYY-MM-DD格式\n",
    "formatted_today = today.strftime('%Y-%m-%d')\n",
    "# formatted_test_day = test_day.strftime('%Y-%m-%d')\n",
    "formatted_start_day = start_day.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fcc91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('today_suggestions.txt', 'w', encoding='utf-8') as today_suggestions,open('history_suggestions.txt', 'a', encoding='utf-8') as history_suggestions:\n",
    "    today_suggestions.write(formatted_today + \"!!!!!!!!~~~~~~~~~~~~~~\\n\")\n",
    "    history_suggestions.write(formatted_today + \"!!!!!!!!!!!~~~~~~~~~~~~\\n\")\n",
    "# df = pd.read_csv('data.csv',  dtype={0: str})\n",
    "df = pd.read_csv('mainboard_stocks_with_prefix.csv', dtype={'code': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10e31cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sz000001</td>\n",
       "      <td>平安银行</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sz000002</td>\n",
       "      <td>万  科Ａ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sz000004</td>\n",
       "      <td>*ST国华</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sz000006</td>\n",
       "      <td>深振业Ａ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sz000007</td>\n",
       "      <td>全新好</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code   name\n",
       "0  sz000001   平安银行\n",
       "1  sz000002  万  科Ａ\n",
       "2  sz000004  *ST国华\n",
       "3  sz000006   深振业Ａ\n",
       "4  sz000007    全新好"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_codes = list(set(df['code']))\n",
    "print(len(df) == len(stock_codes))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe2b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_data_getter(stock_codes, formatted_start_day, formatted_today):\n",
    "    res_ls = []\n",
    "    for stock_code in stock_codes:\n",
    "        # time.sleep(0.8) #avoid abandon from remote\n",
    "        try:\n",
    "            stock_zh_a_hist_df = stock_zh_a_hist_tx(symbol=stock_code, start_date=formatted_start_day, end_date=formatted_today)\n",
    "            if stock_zh_a_hist_df.empty:\n",
    "                print(\"wrong code:\",stock_code)\n",
    "            else:\n",
    "                res_ls.append((stock_code, stock_zh_a_hist_df))\n",
    "        except Exception as e:\n",
    "            print(\"exception:\",e)\n",
    "            logging.error(e)\n",
    "    print(\"stock code:\",stock_codes[-1],\"data collection finished:\", time.time())\n",
    "    return res_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcdb32ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock code: sh603458 data collection finished: 1758416844.0196476\n",
      "stock code: sz000676 data collection finished: 1758416846.3742354\n",
      "stock code: sh601166 data collection finished: 1758416846.4352329\n",
      "stock code: sh605100 data collection finished: 1758416848.6409843\n",
      "stock code: sz000550 data collection finished: 1758416848.692331\n",
      "stock code: sz000779 data collection finished: 1758416849.1004617\n",
      "stock code: sh600128 data collection finished: 1758416849.5760703\n",
      "stock code: sh603958 data collection finished: 1758416850.5739007\n",
      "stock code: sh603115 data collection finished: 1758416850.9257543\n",
      "stock code: sz000151 data collection finished: 1758416851.1916835\n",
      "stock code: sz002191 data collection finished: 1758416851.3470726\n",
      "stock code: sz002932 data collection finished: 1758416851.634125\n",
      "stock code: sh600469 data collection finished: 1758416851.8037398\n",
      "stock code: sz002688 data collection finished: 1758416851.8308196\n",
      "stock code: sz002881 data collection finished: 1758416851.9325323\n",
      "stock code: sz002218 data collection finished: 1758416852.0443282\n",
      "stock code: sh605133 data collection finished: 1758416852.0516787\n",
      "stock code: sh601020 data collection finished: 1758416852.0700107\n",
      "stock code: sz002481 data collection finished: 1758416852.1750097\n",
      "stock code: sz000983 data collection finished: 1758416852.4106555\n",
      "stock code: sz002267 data collection finished: 1758416852.8032722\n",
      "stock code: sh600110 data collection finished: 1758416852.9838297\n",
      "stock code: sh603990 data collection finished: 1758416853.074395\n",
      "stock code: sz002333 data collection finished: 1758416853.0910907\n",
      "stock code: sh600085 data collection finished: 1758416853.2247312\n",
      "stock code: sz002989 data collection finished: 1758416853.235153\n",
      "stock code: sh601857 data collection finished: 1758416853.2385597\n",
      "stock code: sh600135 data collection finished: 1758416853.2446334\n",
      "stock code: sz000603 data collection finished: 1758416853.245642\n",
      "stock code: sz000055 data collection finished: 1758416853.2467027\n",
      "stock code: sh601186 data collection finished: 1758416853.2467027\n",
      "stock code: sh600691 data collection finished: 1758416853.560057\n"
     ]
    }
   ],
   "source": [
    "aspls = np.array_split(stock_codes, logical_cpus)\n",
    "# 然后每个子数组是numpy数组，可以转成列表\n",
    "chunked_list = [arr.tolist() for arr in aspls]\n",
    "\n",
    "process_lock = multiprocessing.Lock()\n",
    "\n",
    "stock_data = []\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=logical_cpus) as executor:\n",
    "    futures = [executor.submit(stock_data_getter, stock_codes_ls, formatted_start_day, formatted_today)\n",
    "        for stock_codes_ls in chunked_list]\n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            result = future.result() \n",
    "            stock_data += result\n",
    "        except Exception as e:\n",
    "            print(\"Error in got results thread:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c20bd998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3032 3032\n"
     ]
    }
   ],
   "source": [
    "print(len(stock_data),len(stock_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bc7036f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  open  close  high   low     volume  turnover_rate\n",
      "0   2025-08-01  3.18   3.20  3.22  3.17   138465.0           1.06\n",
      "1   2025-08-04  3.19   3.21  3.21  3.16   115233.0           0.88\n",
      "2   2025-08-05  3.22   3.22  3.24  3.20   171710.0           1.31\n",
      "3   2025-08-06  3.21   3.19  3.22  3.17   143996.0           1.10\n",
      "4   2025-08-07  3.18   3.18  3.21  3.17   148640.0           1.13\n",
      "5   2025-08-08  3.18   3.22  3.23  3.17   230430.0           1.76\n",
      "6   2025-08-11  3.22   3.26  3.27  3.19   164850.0           1.26\n",
      "7   2025-08-12  3.25   3.24  3.28  3.22   177988.0           1.36\n",
      "8   2025-08-13  3.25   3.22  3.27  3.21   158563.0           1.21\n",
      "9   2025-08-14  3.21   3.13  3.22  3.12   201174.0           1.53\n",
      "10  2025-08-15  3.13   3.14  3.16  3.12   177622.0           1.35\n",
      "11  2025-08-18  3.16   3.19  3.30  3.15   369646.0           2.82\n",
      "12  2025-08-19  3.20   3.28  3.30  3.18   423284.0           3.23\n",
      "13  2025-08-20  3.28   3.34  3.34  3.25   346182.0           2.64\n",
      "14  2025-08-21  3.35   3.32  3.35  3.29   268274.0           2.05\n",
      "15  2025-08-22  3.32   3.31  3.33  3.27   209581.0           1.60\n",
      "16  2025-08-25  3.33   3.29  3.34  3.26   239891.0           1.83\n",
      "17  2025-08-26  3.31   3.62  3.62  3.29   746494.0           5.69\n",
      "18  2025-08-27  3.70   3.47  3.77  3.46  1124791.0           8.58\n",
      "19  2025-08-28  3.55   3.50  3.62  3.40   683052.0           5.21\n",
      "20  2025-08-29  3.47   3.43  3.52  3.41   346394.0           2.64\n",
      "21  2025-09-01  3.45   3.77  3.77  3.41   413435.0           3.15\n",
      "22  2025-09-02  3.88   3.78  4.14  3.73  1573586.0          12.00\n",
      "23  2025-09-03  3.78   3.84  3.92  3.63   917797.0           7.00\n",
      "24  2025-09-04  3.81   3.69  3.84  3.62   671473.0           5.12\n",
      "25  2025-09-05  3.68   3.72  3.73  3.60   541136.0           4.13\n",
      "26  2025-09-08  3.71   3.65  3.72  3.61   390670.0           2.98\n",
      "27  2025-09-09  3.63   3.60  3.66  3.58   345903.0           2.64\n",
      "28  2025-09-10  3.60   3.63  3.65  3.57   253409.0           1.93\n",
      "29  2025-09-11  3.60   3.71  3.73  3.58   472371.0           3.60\n",
      "30  2025-09-12  3.69   3.65  3.75  3.64   353273.0           2.69\n",
      "31  2025-09-15  3.66   3.60  3.67  3.57   280114.0           2.14\n",
      "32  2025-09-16  3.60   3.62  3.64  3.58   264745.0           2.02\n",
      "33  2025-09-17  3.66   3.59  3.69  3.57   317564.0           2.42\n",
      "34  2025-09-18  3.58   3.72  3.95  3.51  1007064.0           7.68\n",
      "35  2025-09-19  3.67   3.80  3.89  3.59  1004163.0           7.66\n"
     ]
    }
   ],
   "source": [
    "print(stock_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd604b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdaspls = np.array_split(np.array(stock_data,  dtype=object), physical_cpus)\n",
    "# sd_chunked_list = [arr.tolist() for arr in sdaspls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dfd9ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_code: sz002453 result: 趋势启动+量价齐升型 \n",
      " \n",
      "XXXXXXstock_code: sh600120 wrong result: 趋势启动+量价齐升型 \n",
      " \n",
      "XXXXXXstock_code: sz000151 wrong result: 趋势启动+量价齐升型 \n",
      " \n",
      "XXXXXXstock_code: sz002174 wrong result: 超跌反转+资金异动型 \n",
      " \n",
      "stock_code: sz002319 result: 超跌反转+资金异动型 \n",
      " \n",
      "stock_code: sh603007 result: 趋势启动+量价齐升型 \n",
      " \n",
      "XXXXXXstock_code: sh600390 wrong result: 趋势启动+量价齐升型 \n",
      " \n",
      "XXXXXXstock_code: sz002803 wrong result: 趋势启动+量价齐升型 \n",
      " \n",
      "wrong count 5\n"
     ]
    }
   ],
   "source": [
    "def check_parameter(stock_codes_ls):\n",
    "    count = 0\n",
    "    for stock_code, stock_zh_df in stock_codes_ls:\n",
    "        open = stock_zh_df[\"open\"]\n",
    "        close = stock_zh_df[\"close\"]\n",
    "        high = stock_zh_df[\"high\"]\n",
    "        low = stock_zh_df[\"low\"]\n",
    "        volume = stock_zh_df[\"volume\"]\n",
    "        turnover = stock_zh_df[\"turnover_rate\"]\n",
    "\n",
    "        ma5 = talib.EMA(close, timeperiod=5)\n",
    "        ma10 = talib.EMA(close, timeperiod=10)\n",
    "        vol_ma5 = talib.EMA(volume, timeperiod=5)\n",
    "        atr = talib.NATR(high, low, close, timeperiod=8) #波动\n",
    "        atr_ma = talib.EMA(atr, timeperiod=5)\n",
    "        macd, macdsignal, macdhist = talib.MACD(close, fastperiod=7, slowperiod=18, signalperiod=6)\n",
    "\n",
    "        rsi = talib.RSI(close, timeperiod=14)  # RSI相对强弱指标\n",
    "        cci = talib.CCI(high, low, close, timeperiod=20)  # 顺势指标\n",
    "        # money_flow = (2*close - low - high) / (high - low) * volume  # 简易资金流\n",
    "        money_flow = talib.MFI(high, low, close, volume, timeperiod=9)\n",
    "        # money_flow_max= money_flow.shift(3).rolling(4).max().iloc[-1]\n",
    "        # turnover_mean= money_flow.shift(1).rolling(5).mean().iloc[-1]\n",
    "        today_candlestick = abs(close.iloc[-3] - open.iloc[-3])\n",
    "        yesterday_candlestick = abs(close.iloc[-4] - open.iloc[-4])\n",
    "        \n",
    "        if (close.iloc[-3] > ma5.iloc[-3] and (ma5.iloc[3] > ma10.iloc[-3]  or (ma5.iloc[-3] > ma5.iloc[-4] > ma5.iloc[-5]))) and \\\n",
    "            rsi.iloc[-3] < 60 and atr.iloc[-3]  > atr_ma.iloc[-3] and open.iloc[-3]  < close.iloc[-3]  * 1.03 and \\\n",
    "                volume.iloc[-3] >= vol_ma5.iloc[-3] * 1.5 and turnover.iloc[-3] > 3 and \\\n",
    "                (macd.iloc[-3] > macdsignal.iloc[-3] and macd.iloc[-4] < macdsignal.iloc[-4] and macdhist.iloc[-3] > abs(macdhist.iloc[-4])):\n",
    "            if close.iloc[-1] > close.iloc[-2]:\n",
    "                print(f\"\"\"stock_code: {stock_code} result: 趋势启动+量价齐升型 \\n \"\"\")\n",
    "            else:\n",
    "                print(f\"\"\"XXXXXXstock_code: {stock_code} wrong result: 趋势启动+量价齐升型 \\n \"\"\")\n",
    "                count += 1\n",
    "        elif (rsi.iloc[-3] < 35) and (cci.iloc[-3] < -100) and \\\n",
    "            today_candlestick > 0.5 * yesterday_candlestick and turnover.iloc[-1] > 3 and \\\n",
    "            money_flow.iloc[-3] > money_flow.iloc[-4]:\n",
    "            if close.iloc[-1] > close.iloc[-2]:\n",
    "                print(f\"\"\"stock_code: {stock_code} result: 超跌反转+资金异动型 \\n \"\"\")\n",
    "            else:\n",
    "                print(f\"\"\"XXXXXXstock_code: {stock_code} wrong result: 超跌反转+资金异动型 \\n \"\"\")\n",
    "                count += 1\n",
    "    print(\"wrong count\", count)\n",
    "\n",
    "check_parameter(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "007a97d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ProcessPoolExecutor(max_workers=physical_cpus) as executor:\n",
    "#     futures = [executor.submit(check_parameter, sd_ls)\n",
    "#         for sd_ls in sd_chunked_list]\n",
    "#     for future in as_completed(futures):\n",
    "#         try:\n",
    "#             future.result() \n",
    "#         except Exception as e:\n",
    "#             print(\"Error in process:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a8447d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_code: sh600530 result: 趋势启动+量价齐升型 \n",
      " \n",
      "stock_code: sz002370 result: 超跌反转+资金异动型 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "def run_analysis(stock_codes_ls):\n",
    "    res_ls = []\n",
    "    for stock_code, stock_zh_df in stock_codes_ls:\n",
    "        open = stock_zh_df[\"open\"]\n",
    "        close = stock_zh_df[\"close\"]\n",
    "        high = stock_zh_df[\"high\"]\n",
    "        low = stock_zh_df[\"low\"]\n",
    "        volume = stock_zh_df[\"volume\"]\n",
    "        turnover = stock_zh_df[\"turnover_rate\"]\n",
    "\n",
    "        ma5 = talib.EMA(close, timeperiod=5)\n",
    "        ma10 = talib.EMA(close, timeperiod=10)\n",
    "        vol_ma5 = talib.EMA(volume, timeperiod=5)\n",
    "        atr = talib.NATR(high, low, close, timeperiod=8)\n",
    "        atr_ma = talib.EMA(atr, timeperiod=5)\n",
    "        macd, macdsignal, macdhist = talib.MACD(close, fastperiod=7, slowperiod=18, signalperiod=6)#快速EMA：6~8，慢速EMA：15~20，信号线：5~7\n",
    "\n",
    "        rsi = talib.RSI(close, timeperiod=14)  # RSI相对强弱指标\n",
    "        cci = talib.CCI(high, low, close, timeperiod=20)  # 顺势指标\n",
    "        # money_flow = (2*close - low - high) / (high - low) * volume  # 简易资金流\n",
    "        money_flow = talib.MFI(high, low, close, volume, timeperiod=9)\n",
    "        # money_flow_max= money_flow.shift(1).rolling(4).max().iloc[-1]\n",
    "        # turnover_mean= money_flow.shift(1).rolling(5).mean().iloc[-1]\n",
    "        today_candlestick = abs(close.iloc[-1] - open.iloc[-1])\n",
    "        yesterday_candlestick = abs(close.iloc[-2] - open.iloc[-2])\n",
    "\n",
    "        if close.iloc[-1] > ma5.iloc[-1] and (ma5.iloc[1] > ma10.iloc[-1] or (ma5.iloc[-1] > ma5.iloc[-2] > ma5.iloc[-3])) and \\\n",
    "                rsi.iloc[-1] < 60 and atr.iloc[-1]  > atr_ma.iloc[-1] and open.iloc[-1]  < close.iloc[-1]  * 1.03 and \\\n",
    "                volume.iloc[-1] >= vol_ma5.iloc[-1] * 1.5 and turnover.iloc[-1] > 3 and \\\n",
    "                macd.iloc[-1] > macdsignal.iloc[-1] and macd.iloc[-2] < macdsignal.iloc[-2] and macdhist.iloc[-1] > abs(macdhist.iloc[-2]):\n",
    "            res_ls.append(f\"\"\"stock_code: {stock_code} result: 趋势启动+量价齐升型 \\n \"\"\")\n",
    "        elif (rsi.iloc[-1] < 35) and (cci.iloc[-1] < -100) and \\\n",
    "            today_candlestick > 0.5 * yesterday_candlestick and turnover.iloc[-1] > 3 and \\\n",
    "            money_flow.iloc[-1] > money_flow.iloc[-2]:\n",
    "            res_ls.append(f\"\"\"stock_code: {stock_code} result: 超跌反转+资金异动型 \\n \"\"\")\n",
    "\n",
    "    for result in res_ls:\n",
    "        print(result)\n",
    "    # with open('today_suggestions.txt', 'a', encoding='utf-8') as today_suggestions,open('history_suggestions.txt', 'a', encoding='utf-8') as history_suggestions:\n",
    "    #     for result in res_ls:\n",
    "    #         today_suggestions.write(result)\n",
    "    #         history_suggestions.write(result)\n",
    "\n",
    "\n",
    "run_analysis(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0d37891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ProcessPoolExecutor(max_workers=physical_cpus) as executor:\n",
    "#     futures = [executor.submit(run_analysis, args=(stock_codes_ls, process_lock))\n",
    "#         for stock_codes_ls in chunked_list]\n",
    "#     for future in as_completed(futures):\n",
    "#         try:\n",
    "#             future.result() \n",
    "#         except Exception as e:\n",
    "#             print(\"Error in thread:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccd560fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validate_proxy(proxies, result_queue):\n",
    "#     \"\"\"验证代理有效性 [6]()\"\"\"\n",
    "#     test_url = \"http://icanhazip.com\"   # 测试网站 \n",
    "#     for proxy in proxies:\n",
    "#         # print(\"Testing proxy:\", proxy)\n",
    "#         try:\n",
    "#             start_time = time.time() \n",
    "#             resp = requests.get(test_url,  proxies=proxy, timeout=5)\n",
    "#             latency = int((time.time()  - start_time))  # 计算延迟 \n",
    "#             # print(resp.status_code, type(resp.status_code),resp.text,proxy)\n",
    "#             if resp.status_code  == 200:\n",
    "#                 result_queue.put((latency, proxy))\n",
    "#         except Exception:\n",
    "#             pass\n",
    "\n",
    "# proxies_map = []\n",
    "# response = requests.get('https://api.proxyscrape.com/v4/free-proxy-list/get?request=display_proxies&proxy_format=protocolipport&format=text',  timeout=30)\n",
    "# if response.status_code == 200:\n",
    "#     proxies = response.text.replace(\"socks4\",  \"https\")\n",
    "#     proxies_ls = [proxy for proxy in proxies.split('\\r\\n')  if proxy != \"\"]\n",
    "\n",
    "#     for url in proxies_ls:\n",
    "#         try:\n",
    "#             # 按 \"://\" 分割协议和地址（最多分割1次）\n",
    "#             protocol, _address = url.split('://',  1)\n",
    "#             if protocol == \"http\":\n",
    "#                 proxies_map.append({protocol: url})\n",
    "#         except ValueError:\n",
    "#             # 处理无效格式（如缺少 ://）\n",
    "#             print(f\"跳过无效URL: {url}\")\n",
    "#     print(proxies_map)\n",
    "# aspls = np.array_split(proxies_map, logical_cpus)\n",
    "# # 然后每个子数组是numpy数组，可以转成列表\n",
    "# chunked_list = [arr.tolist() for arr in aspls]\n",
    "\n",
    "# validate_proxies_queue = queue.Queue()\n",
    "# validate_proxies_ls = []\n",
    "\n",
    "# process_lock = multiprocessing.Lock()\n",
    "\n",
    "# with ThreadPoolExecutor(max_workers=logical_cpus) as executor:\n",
    "#     futures = [executor.submit(validate_proxy, proxies, validate_proxies_queue)\n",
    "#         for proxies in chunked_list]\n",
    "#     for future in as_completed(futures):\n",
    "#         try:\n",
    "#             future.result()\n",
    "#         except Exception as e:\n",
    "#             print(\"Error in got results thread:\", e)\n",
    "\n",
    "# while not validate_proxies_queue.empty():\n",
    "#     validate_proxies_ls.append(validate_proxies_queue.get())\n",
    "\n",
    "# validate_proxies_ls =sorted(validate_proxies_ls, key=lambda x: x[0])\n",
    "# for i in validate_proxies_ls:\n",
    "#     validate_proxies_queue.put(i[1])\n",
    "\n",
    "# print(validate_proxies_ls)\n",
    "# print(len(validate_proxies_ls))\n",
    "# print(validate_proxies_queue.empty())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76582855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stock_data_getter_with_proxies(stock_codes, formatted_start_day, formatted_today, validate_proxies_queue):\n",
    "#     res_ls = []\n",
    "#     if validate_proxies_queue.empty():\n",
    "#         return []\n",
    "#     proxy = validate_proxies_queue.get()\n",
    "#     i = 0\n",
    "#     while i < len(stock_codes):\n",
    "#         time.sleep(0.8) #avoid abandon from remote\n",
    "#         stock_code = stock_codes[i]\n",
    "#         i += 1\n",
    "#         stock_zh_a_hist_df = kline_daily.stock_zh_a_hist_with_proxy(symbol=stock_code, start_date=formatted_start_day, end_date=formatted_today, proxy={\"http\":proxy[\"http\"]})\n",
    "#         if stock_zh_a_hist_df is None:\n",
    "#             if validate_proxies_queue.empty():\n",
    "#                 print(\"proxy ran out\")\n",
    "#                 return []\n",
    "#             proxy = validate_proxies_queue.get()\n",
    "#             i -= 1\n",
    "#         elif stock_zh_a_hist_df.empty:\n",
    "#             print(\"wrong code:\",stock_code)\n",
    "#         else:\n",
    "#             res_ls.append((stock_code, stock_zh_a_hist_df))\n",
    "#     print(\"stock code:\",stock_codes[-1],\"data collection finished:\", time.time())\n",
    "#     return res_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0f4d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect_and_analyze_data([\"000001\",\"000002\"], log_phy_ratio, formatted_start_day, formatted_today, lock, run_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d038d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sd = ak.stock_zh_a_hist(symbol=\"000001\", period=\"daily\", start_date=formatted_start_day, end_date=formatted_today, adjust=\"\")\n",
    "# print(sd)\n",
    "# df_shanghai = ak.index_zh_a_hist( \n",
    "#     symbol=\"000001\",      # 上证指数代码（固定为000001）\n",
    "#     period=\"daily\",       # 数据周期：daily（日线）、weekly（周线）、monthly（月线）\n",
    "#     start_date=\"20200101\", # 起始日期（格式：YYYYMMDD）\n",
    "#     end_date=\"20250904\",   # 结束日期（默认为当前日期）\n",
    "# )\n",
    "\n",
    "# # 查看前5行数据 \n",
    "# print(df_shanghai.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18438774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_mainboard_stocks_ak():\n",
    "#     \"\"\"使用akshare获取主板股票列表\"\"\"\n",
    "#     # 获取所有上市公司的基本信息\n",
    "#     stock_info = ak.stock_info_a_code_name()\n",
    "    \n",
    "#     # 筛选主板股票\n",
    "#     mainboard_stocks = stock_info[stock_info['code'].str.startswith(('600', '601', '603', '605', '000', '002'))]\n",
    "    \n",
    "#     return mainboard_stocks\n",
    "\n",
    "# # 获取主板股票\n",
    "# mainboard_stocks_ak = get_mainboard_stocks_ak()\n",
    "# print(mainboard_stocks_ak.head())\n",
    "# mainboard_stocks_ak.to_csv('mainboard_stocks.csv', index=False, encoding='utf-8-sig')\n",
    "# def add_stock_prefix(code):\n",
    "#     code_str = str(code).zfill(6)  # 确保代码为6位字符串 \n",
    "#     if code_str.startswith('6'):    # 上证\n",
    "#         return 'sh' + code_str\n",
    "#     elif code_str.startswith(('0',  '3')):  # 深证\n",
    "#         return 'sz' + code_str \n",
    "#     return code_str  # 其他情况保留原格式 \n",
    "# mainboard_stocks_ak['code'] = mainboard_stocks_ak['code'].apply(add_stock_prefix)\n",
    "# mainboard_stocks_ak.to_csv('mainboard_stocks_with_prefix.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a612a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # date=\"20200331\"; choice of {\"XXXX0331\", \"XXXX0630\", \"XXXX0930\", \"XXXX1231\"}; 从 20081231 开始\n",
    "# stock_yjyg_em_df = ak.stock_yjyg_em(date=\"20250630\")\n",
    "# stock_yjyg_em_df_sorted_desc = stock_yjyg_em_df.sort_values(by=stock_yjyg_em_df.columns[6], ascending=False) #'业绩变动幅度'\n",
    "# # print(stock_yjyg_em_df_sorted_desc.head(10))\n",
    "# print(stock_yjyg_em_df_sorted_desc.iloc[:, [1,6]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "856e634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ProxyManager:\n",
    "#     \"\"\"代理IP管理器\"\"\"\n",
    "\n",
    "#     def __init__(self, proxy_api_url, max_retry=3):\n",
    "#         self.proxy_api_url = proxy_api_url\n",
    "#         self.max_retry = max_retry\n",
    "\n",
    "#     def get_valid_proxy(self):\n",
    "#         \"\"\"获取有效的代理IP\"\"\"\n",
    "#         for attempt in range(self.max_retry):\n",
    "#             try:\n",
    "#                 resp = requests.get(self.proxy_api_url, timeout=5)\n",
    "#                 proxy_json = resp.json()\n",
    "#                 proxy_data = proxy_json[\"data\"][0]\n",
    "#                 server = proxy_data[\"server\"]\n",
    "#                 ip, port = server.split(\":\")\n",
    "#                 proxy = {\"http\": f\"http://{ip}:{port}\", \"https\": f\"http://{ip}:{port}\"}\n",
    "\n",
    "#                 # 验证代理可用性\n",
    "#                 test_url = \"http://quote.eastmoney.com\"\n",
    "#                 test = requests.get(test_url, proxies=proxy, timeout=5)\n",
    "#                 if test.status_code == 200:\n",
    "#                     print(f\"代理可用: {ip}:{port}\")\n",
    "#                     return proxy\n",
    "#             except Exception as e:\n",
    "#                 print(f\"获取代理失败，第{attempt + 1}次尝试: {e}\")\n",
    "\n",
    "#         print(f\"未能获取有效代理\")\n",
    "#         return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
