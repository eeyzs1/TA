{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a97e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from akshare.utils import demjson\n",
    "from akshare.utils.tqdm import get_tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de3500c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442\n"
     ]
    }
   ],
   "source": [
    "start_year = \"2020\"\n",
    "\n",
    "headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/89.0.4389.90 Safari/537.36\",\n",
    "    }\n",
    "headers_bk = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/89.0.4389.90 Safari/537.36\",\n",
    "            \"Referer\": \"https://q.10jqka.com.cn\",\n",
    "            \"Host\": \"d.10jqka.com.cn\",\n",
    "        }\n",
    "\n",
    "link_code_ls = []\n",
    "bk_data_ls = []\n",
    "today_data_ls = []\n",
    "\n",
    "for suffix in [\"gn/\",\"thshy/\"]:\n",
    "    url = f\"https://q.10jqka.com.cn/{suffix}\"\n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(r.text, features=\"lxml\")\n",
    "    divs = soup.find_all(name=\"div\", attrs={\"class\": \"cate_items\"})\n",
    "    for div in divs:\n",
    "        # 在每个div中查找所有的a标签\n",
    "        links = div.find_all('a') \n",
    "        for link in links:\n",
    "            # 获取href属性\n",
    "            href = link.get('href') \n",
    "            # 获取文本内容\n",
    "            text = link.text \n",
    "            link_code_ls.append((href,  text))\n",
    "\n",
    "print(len(link_code_ls))\n",
    "for symbol_url, name in link_code_ls[:2]:\n",
    "    r = requests.get(symbol_url, headers=headers)\n",
    "    soup = BeautifulSoup(r.text, features=\"lxml\")\n",
    "    symbol_code = soup.find(name=\"div\", attrs={\"class\": \"board-hq\"}).find(\"span\").text\n",
    "    big_df = pd.DataFrame()\n",
    "    current_year = datetime.now().year\n",
    "    dd_texts = [dd.text for dd in soup.find_all(\"dd\")] \n",
    "    close = soup.find(\"span\",  class_=\"board-xj arr-fall\").text \n",
    "    open, low, high, volume, amount = dd_texts[0], dd_texts[2], dd_texts[3], dd_texts[4], dd_texts[9]\n",
    "    today_data_ls.append((name, symbol_code, open, high, low, close, volume, amount))\n",
    "\n",
    "    tqdm = get_tqdm()\n",
    "    for year in tqdm(range(int(start_year), current_year + 1), leave=False):\n",
    "        url = f\"https://d.10jqka.com.cn/v4/line/bk_{symbol_code}/01/{year}.js\"\n",
    "        r = requests.get(url, headers=headers_bk)\n",
    "        data_text = r.text\n",
    "        try:\n",
    "            demjson.decode(data_text[data_text.find(\"{\") : -1])\n",
    "        except:  # noqa: E722\n",
    "            continue\n",
    "        temp_df = demjson.decode(data_text[data_text.find(\"{\") : -1])\n",
    "        temp_df = pd.DataFrame(temp_df[\"data\"].split(\";\"))\n",
    "        temp_df = temp_df.iloc[:, 0].str.split(\",\", expand=True)\n",
    "        big_df = pd.concat(objs=[big_df, temp_df], ignore_index=True)\n",
    "    if big_df.columns.shape[0] == 12:\n",
    "        big_df.columns = [\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\",\"amount\",\"_\",\"_\",\"_\",\"_\",\"_\",]\n",
    "    else:\n",
    "        big_df.columns = [\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\",\"amount\",\"_\",\"_\",\"_\",\"_\",]\n",
    "    big_df = big_df[[\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\",\"amount\",]]\n",
    "    big_df[\"date\"] = pd.to_datetime(big_df[\"date\"], errors=\"coerce\").dt.date\n",
    "    big_df[\"open\"] = pd.to_numeric(big_df[\"open\"], errors=\"coerce\")\n",
    "    big_df[\"high\"] = pd.to_numeric(big_df[\"high\"], errors=\"coerce\")\n",
    "    big_df[\"low\"] = pd.to_numeric(big_df[\"low\"], errors=\"coerce\")\n",
    "    big_df[\"close\"] = pd.to_numeric(big_df[\"close\"], errors=\"coerce\")\n",
    "    big_df[\"volume\"] = pd.to_numeric(big_df[\"volume\"], errors=\"coerce\")\n",
    "    big_df[\"amount\"] = pd.to_numeric(big_df[\"amount\"], errors=\"coerce\")\n",
    "    bk_data_ls.append((name, big_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "802ac574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "阿尔茨海默概念\n",
      "           date      open      high       low     close     volume  \\\n",
      "472  2025-09-02  1353.379  1353.603  1320.547  1330.656  982424350   \n",
      "473  2025-09-03  1333.546  1343.817  1317.655  1322.170  813860100   \n",
      "474  2025-09-04  1326.883  1337.293  1294.136  1313.114  837025920   \n",
      "475  2025-09-05  1312.889  1335.951  1290.293  1335.951  693464640   \n",
      "476  2025-09-08  1336.437  1356.452  1335.287  1353.549  705241630   \n",
      "\n",
      "           amount  \n",
      "472  1.789247e+10  \n",
      "473  1.646862e+10  \n",
      "474  1.476401e+10  \n",
      "475  1.385096e+10  \n",
      "476  1.465946e+10  \n"
     ]
    }
   ],
   "source": [
    "print(bk_data_ls[0][0])\n",
    "print(bk_data_ls[0][1].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a9e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn  as nn\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing  import MinMaxScaler\n",
    "from torch.utils.data  import Dataset, DataLoader\n",
    " \n",
    "# ===== 1. 数据预处理 ===== \n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data  import Dataset\n",
    "from sklearn.preprocessing  import MinMaxScaler\n",
    " \n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, bk_data_ls, seq_length=16, forecast_gap=2):\n",
    "        \"\"\"\n",
    "        bk_data_ls: List of tuples (code, data), where:\n",
    "            - code: 股票代码（str）\n",
    "            - data: DataFrame，列顺序为 [open, high, low, close, volume, amount]\n",
    "        seq_length_short: 短期序列长度（可选）\n",
    "        seq_length: 长期依赖序列长度（用于输入）\n",
    "        forecast_gap: 预测几天后的收盘价，如后天 = 2\n",
    "        \"\"\"\n",
    "        self.seq_length  = seq_length\n",
    "        self.forecast_gap  = forecast_gap\n",
    "        self.scalers  = dict()  # 存储每个股票的归一化器\n",
    " \n",
    "        all_X = []\n",
    "        all_y = []\n",
    " \n",
    "        # 遍历多个股票数据 \n",
    "        for code, data in bk_data_ls:\n",
    "            # 数据标准化\n",
    "            scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "            scaled_data = scaler.fit_transform(data) \n",
    "            self.scalers[code]  = scaler  # 保存 scaler 供后续使用 \n",
    " \n",
    "            # 构造样本\n",
    "            X, y = [], []\n",
    "            max_index = len(data) - seq_length - forecast_gap\n",
    "            for i in range(max_index):\n",
    "                # 输入序列：seq_length 天的特征\n",
    "                seq_features = scaled_data[i:i + seq_length]\n",
    "                # 标签：forecast_gap 天后的收盘价（第3列）\n",
    "                target_idx = i + seq_length + forecast_gap - 1\n",
    "                target_close = scaled_data[target_idx, 3]\n",
    " \n",
    "                X.append(seq_features) \n",
    "                y.append(target_close) \n",
    " \n",
    "            # 转换为 numpy 并保存 \n",
    "            all_X.extend(X) \n",
    "            all_y.extend(y) \n",
    " \n",
    "        # 统一转换为 tensor\n",
    "        self.X = torch.tensor(np.array(all_X),  dtype=torch.float32) \n",
    "        self.y = torch.tensor(np.array(all_y),  dtype=torch.float32).view(-1,  1)\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    " \n",
    "    def get_scaler(self, code):\n",
    "        \"\"\"\n",
    "        获取指定股票的 scaler\n",
    "        \"\"\"\n",
    "        return self.scalers.get(code,  None)\n",
    "    def update_scaler(self, new_data_ls):\n",
    "        \"\"\"用新数据增量更新各股票的Scaler\"\"\"\n",
    "        for code, new_data in new_data_ls:\n",
    "            if code in self.scalers: \n",
    "                scaler = self.scalers[code] \n",
    "                # 增量更新：扩展 min/max 范围 \n",
    "                scaler.partial_fit(new_data)   # 关键步骤 \n",
    "\n",
    "\n",
    "class MultiScaleAttentionLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size = 64, num_layers_long = 3, num_layers_short = 2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm_long  = nn.LSTM(input_size, hidden_size, num_layers=num_layers_long, batch_first=True, dropout=0.2 if num_layers_long > 1 else 0)\n",
    "        self.lstm_short  = nn.LSTM(input_size, hidden_size, num_layers=num_layers_short, batch_first=True, dropout=0.2 if num_layers_short > 1 else 0)\n",
    "        self.attn  = nn.MultiheadAttention(hidden_size, num_heads=4)  # 4头注意力 \n",
    "        \n",
    "        self.regressor  = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 32),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    " \n",
    "    def forward(self, x1, seq_length_short=7):\n",
    "        out1, _ = self.lstm_long(x1) \n",
    "        out2, _ = self.lstm_short(x1[:, -seq_length_short:, :]) # lstm_out: [batch, seq_len, hidden]\n",
    "        lstm_out = torch.cat((out1,  out2), dim=1)\n",
    "        attn_out = self.attn(lstm_out,  lstm_out, lstm_out, batch_first=True, need_weights=False) \n",
    "        out = self.regressor(attn_out[:, -1, :]) \n",
    "        return out\n",
    "\n",
    " \n",
    "# ===== 3. 训练配置 =====\n",
    "if __name__ == \"__main__\":\n",
    "    # 加载数据 (示例)\n",
    "    data = pd.read_csv('stock.csv',  usecols=['open','high','low','close','volume','amount'])\n",
    "    \n",
    "    # 创建数据集 \n",
    "    dataset = StockDataset(data, seq_length=10, forecast_gap=2)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    train_set, test_set = torch.utils.data.random_split( \n",
    "        dataset, [train_size, len(dataset) - train_size]\n",
    "    )\n",
    "    \n",
    "    # 数据加载器 \n",
    "    train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=32)\n",
    "    \n",
    "    # 模型初始化\n",
    "    device = torch.device('cuda'  if torch.cuda.is_available()  else 'cpu')\n",
    "    model = MultiScaleAttentionLSTM(\n",
    "        input_size=6,  # 6个特征 \n",
    "        hidden_size=64,\n",
    "        num_layers=2\n",
    "    ).to(device)\n",
    "    \n",
    "    # 训练参数 \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(),  lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( \n",
    "        optimizer, \n",
    "        mode='min',       # 监控验证损失\n",
    "        factor=0.5,       # 学习率衰减系数 \n",
    "        patience=5,       # 容忍5个epoch无改善\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # ===== 4. 训练循环 =====\n",
    "    for epoch in range(100):\n",
    "        model.train() \n",
    "        train_loss = 0 \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device),  y_batch.to(device) \n",
    "            \n",
    "            optimizer.zero_grad() \n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward() \n",
    "            nn.utils.clip_grad_norm_(model.parameters(),  1.0)  # 梯度裁剪\n",
    "            optimizer.step() \n",
    "            train_loss += loss.item() \n",
    "        \n",
    "        # 验证\n",
    "        model.eval() \n",
    "        test_loss = 0\n",
    "        with torch.no_grad(): \n",
    "            for X_test, y_test in test_loader:\n",
    "                X_test, y_test = X_test.to(device),  y_test.to(device) \n",
    "                preds = model(X_test)\n",
    "                test_loss += criterion(preds, y_test).item()\n",
    "        \n",
    "        scheduler.step(test_loss) \n",
    "        print(f'Epoch {epoch} | Train Loss: {train_loss/len(train_loader):.6f} | Test Loss: {test_loss/len(test_loader):.6f}')\n",
    " \n",
    "    # ===== 5. 预测示例 =====\n",
    "    model.eval() \n",
    "    with torch.no_grad(): \n",
    "        sample = test_set[0][0].unsqueeze(0).to(device)\n",
    "        prediction = model(sample)\n",
    "        scaled_pred = prediction.cpu().numpy() \n",
    "        \n",
    "        # 逆归一化收盘价 \n",
    "        dummy = np.zeros((1,  6))\n",
    "        dummy[:, 3] = scaled_pred  # 将预测值放入close列\n",
    "        real_pred = dataset.scaler_close.inverse_transform(dummy)[0,  3]\n",
    "        print(f'预测的后天收盘价: {real_pred:.2f}')\n",
    "\n",
    "\n",
    "# 假设已存在训练好的 dataset 对象 \n",
    "new_data = [('000001.SZ', df_new_000001), ('600000.SH', df_new_600000)]\n",
    " \n",
    "# 增量更新Scaler并微调模型 \n",
    "dataset.update_scaler(new_data)   # 更新Scaler范围\n",
    "new_X = dataset.transform_new_data(new_data)   # 用新Scaler转换数据\n",
    " \n",
    "# 模型微调（非重新训练）\n",
    "optimizer = torch.optim.SGD(model.parameters(),  lr=0.001)  # 使用更小学习率 \n",
    "for epoch in range(5):\n",
    "    for X_batch, y_batch in DataLoader(new_X, batch_size=32):\n",
    "        optimizer.zero_grad() \n",
    "        loss = model(X_batch, y_batch)\n",
    "        loss.backward() \n",
    "        optimizer.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1a6d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734c8eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b84f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3ed238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
