{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a97e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from akshare.utils import demjson\n",
    "from akshare.utils.tqdm import get_tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn  as nn\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing  import MinMaxScaler\n",
    "from torch.utils.data  import Dataset, DataLoader\n",
    " \n",
    "# ===== 1. 数据预处理 ===== \n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data  import Dataset\n",
    "from sklearn.preprocessing  import MinMaxScaler\n",
    "import joblib\n",
    "import os\n",
    "from torch  import amp \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de3500c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24224653c77942f09e9a6934c435490f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac006c63cf7409384ba61a4075042e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_year = \"2023\"\n",
    "\n",
    "headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/89.0.4389.90 Safari/537.36\",\n",
    "    }\n",
    "headers_bk = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/89.0.4389.90 Safari/537.36\",\n",
    "            \"Referer\": \"https://q.10jqka.com.cn\",\n",
    "            \"Host\": \"d.10jqka.com.cn\",\n",
    "        }\n",
    "\n",
    "link_code_ls = []\n",
    "bk_data_ls = []\n",
    "code_ls = []\n",
    "\n",
    "for suffix in [\"gn/\",\"thshy/\"]:\n",
    "    url = f\"https://q.10jqka.com.cn/{suffix}\"\n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(r.text, features=\"lxml\")\n",
    "    divs = soup.find_all(name=\"div\", attrs={\"class\": \"cate_items\"})\n",
    "    for div in divs:\n",
    "        # 在每个div中查找所有的a标签\n",
    "        links = div.find_all('a') \n",
    "        for link in links:\n",
    "            # 获取href属性\n",
    "            href = link.get('href') \n",
    "            # 获取文本内容\n",
    "            text = link.text \n",
    "            link_code_ls.append((href,  text))\n",
    "\n",
    "print(len(link_code_ls))\n",
    "for symbol_url, name in link_code_ls:\n",
    "    r = requests.get(symbol_url, headers=headers)\n",
    "    soup_today = BeautifulSoup(r.text, features=\"lxml\")\n",
    "    symbol_code = soup_today.find(name=\"div\", attrs={\"class\": \"board-hq\"}).find(\"span\").text\n",
    "    big_df = pd.DataFrame()\n",
    "    current_year = datetime.now().year\n",
    "\n",
    "    tqdm = get_tqdm()\n",
    "    for year in tqdm(range(int(start_year), current_year + 1), leave=False):\n",
    "        url = f\"https://d.10jqka.com.cn/v4/line/bk_{symbol_code}/01/{year}.js\"\n",
    "        r = requests.get(url, headers=headers_bk)\n",
    "        data_text = r.text\n",
    "        try:\n",
    "            demjson.decode(data_text[data_text.find(\"{\") : -1])\n",
    "        except:  # noqa: E722\n",
    "            continue\n",
    "        temp_df = demjson.decode(data_text[data_text.find(\"{\") : -1])\n",
    "        temp_df = pd.DataFrame(temp_df[\"data\"].split(\";\"))\n",
    "        temp_df = temp_df.iloc[:, 0].str.split(\",\", expand=True)\n",
    "        big_df = pd.concat(objs=[big_df, temp_df], ignore_index=True)\n",
    "    if big_df.columns.shape[0] == 12:\n",
    "        big_df.columns = [\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\",\"amount\",\"_\",\"_\",\"_\",\"_\",\"_\",]\n",
    "    else:\n",
    "        big_df.columns = [\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\",\"amount\",\"_\",\"_\",\"_\",\"_\",]\n",
    "    big_df = big_df[[\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\",\"amount\",]]\n",
    "    big_df.insert(1,  'code', symbol_code)\n",
    "    big_df[\"date\"] = pd.to_datetime(big_df[\"date\"], errors=\"coerce\").dt.date\n",
    "    big_df[\"code\"] = pd.to_numeric(big_df[\"code\"], errors=\"coerce\")\n",
    "    big_df[\"open\"] = pd.to_numeric(big_df[\"open\"], errors=\"coerce\")\n",
    "    big_df[\"high\"] = pd.to_numeric(big_df[\"high\"], errors=\"coerce\")\n",
    "    big_df[\"low\"] = pd.to_numeric(big_df[\"low\"], errors=\"coerce\")\n",
    "    big_df[\"close\"] = pd.to_numeric(big_df[\"close\"], errors=\"coerce\")\n",
    "    big_df[\"volume\"] = pd.to_numeric(big_df[\"volume\"], errors=\"coerce\")\n",
    "    big_df[\"amount\"] = pd.to_numeric(big_df[\"amount\"], errors=\"coerce\")\n",
    "    \n",
    "\n",
    "    if big_df[\"date\"].iloc[-1] != datetime.now().date():\n",
    "        dd_texts = [dd.text for dd in soup_today.find_all(\"dd\")] \n",
    "        close = soup_today.find(\"span\",  class_=\"board-xj arr-fall\").text \n",
    "        open, low, high, volume, amount = dd_texts[0], dd_texts[2], dd_texts[3], dd_texts[4], dd_texts[9]\n",
    "        new_list = [\n",
    "            datetime.now().date(),\n",
    "            float(symbol_code),\n",
    "            float(open),\n",
    "            float(high),\n",
    "            float(low),\n",
    "            float(close),\n",
    "            float(volume.replace(\",\", \"\")),\n",
    "            float(amount.replace(\",\", \"\")),\n",
    "        ]\n",
    "        new_row = pd.DataFrame([new_list], columns=big_df.columns) \n",
    "        result_df = pd.concat([big_df,  new_row], ignore_index=True)\n",
    "    bk_data_ls.append((name, symbol_code, big_df))\n",
    "    code_ls.append(symbol_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "802ac574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "阿尔茨海默概念\n",
      "886056\n",
      "           date      open      high       low     close     volume  \\\n",
      "475  2025-09-05  1312.889  1335.951  1290.293  1335.951  693464640   \n",
      "476  2025-09-08  1336.437  1356.452  1335.287  1353.549  705241630   \n",
      "477  2025-09-09  1350.358  1355.748  1322.282  1327.323  676046110   \n",
      "478  2025-09-10  1325.734  1339.842  1319.055  1327.358  510316830   \n",
      "479  2025-09-11  1315.080  1321.839  1287.400  1321.839  437438020   \n",
      "\n",
      "           amount  \n",
      "475  1.385096e+10  \n",
      "476  1.465946e+10  \n",
      "477  1.260683e+10  \n",
      "478  9.774379e+09  \n",
      "479  8.368500e+09  \n"
     ]
    }
   ],
   "source": [
    "print(bk_data_ls[0][0])\n",
    "print(bk_data_ls[0][1])\n",
    "print(bk_data_ls[0][2].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94708784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_Scalers(scalers, filepath):\n",
    "    \"\"\"保存所有股票的Scaler到文件\"\"\"\n",
    "    joblib.dump(scalers, filepath)\n",
    "def load_Scalers(filepath):\n",
    "    if os.path.exists(filepath):\n",
    "        return joblib.load(filepath)\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badcc5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_scaler_path = \"./model/code_scaler.save\"\n",
    "if os.path.exists(code_scaler_path):\n",
    "    joblib.load(code_scaler_path)\n",
    "else:\n",
    "    code_df = pd.DataFrame(code_ls, columns=['code'])\n",
    "    code_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    code_scaler.fit(code_df)\n",
    "    save_Scalers(code_scaler, code_scaler_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba57affa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "    def __init__(self, bk_data_ls, seq_length=16, forecast_gap=2, scaler_filepath='./model/scalers.sav'):\n",
    "        \"\"\"\n",
    "        bk_data_ls: List of tuples (code, data), where:\n",
    "            - code: 股票代码（str）\n",
    "            - data: DataFrame，列顺序为 [open, high, low, close, volume, amount]\n",
    "        seq_length_short: 短期序列长度（可选）\n",
    "        seq_length: 长期依赖序列长度（用于输入）\n",
    "        forecast_gap: 预测几天后的收盘价，如后天 = 2\n",
    "        \"\"\"\n",
    "        self.seq_length  = seq_length\n",
    "        self.forecast_gap  = forecast_gap\n",
    "        self.scalers  = load_Scalers(scaler_filepath) # 存储每个股票的归一化器\n",
    " \n",
    "        all_X = []\n",
    "        all_y = []\n",
    "\n",
    "        for _name, code, data in bk_data_ls:\n",
    "            data = data[[\"open\", \"high\", \"low\", \"close\", \"volume\", \"amount\"]]\n",
    "            if code in self.scalers:\n",
    "                scaler = self.scalers[code]\n",
    "                scaled_data = scaler.partial_fit(data).transform(data) \n",
    "                self.scalers[code]  = scaler  # 保存 scaler 供后续使用 \n",
    "            else:\n",
    "                scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "                scaled_data = scaler.fit_transform(data) \n",
    "                self.scalers[code]  = scaler  # 保存 scaler 供后续使用 \n",
    "    \n",
    "            # 构造样本\n",
    "            X, y = [], []\n",
    "            max_index = len(data) - seq_length - forecast_gap\n",
    "            for i in range(max_index):\n",
    "                # 输入序列：seq_length 天的特征\n",
    "                seq_features = scaled_data[i:i + seq_length]\n",
    "                code_feature = code_scaler.transform(data[['code']].iloc[i:i + seq_length])\n",
    "                seq_features = np.insert(seq_features,  1, code_feature, axis=1) \n",
    "                # 标签：forecast_gap 天后的收盘价（第3列）\n",
    "                target_idx = i + seq_length + forecast_gap - 1\n",
    "                target_close = scaled_data[target_idx, 3]\n",
    " \n",
    "                X.append(seq_features) \n",
    "                y.append(target_close) \n",
    " \n",
    "            # 转换为 numpy 并保存 \n",
    "            all_X.extend(X) \n",
    "            all_y.extend(y) \n",
    " \n",
    "        # 统一转换为 tensor\n",
    "        self.X = torch.tensor(np.array(all_X),  dtype=torch.float16) \n",
    "        self.y = torch.tensor(np.array(all_y),  dtype=torch.float16).view(-1,  1)\n",
    "        save_Scalers(self.scalers, scaler_filepath)  # 保存所有股票的Scaler\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    " \n",
    "    def get_scaler(self, code):\n",
    "        return self.scalers.get(code,  None)\n",
    "    def inverse_transform(self, code, scaled_values):\n",
    "        \"\"\"逆归一化\"\"\"\n",
    "        scaler = self.get_scaler(code)\n",
    "        if scaler:\n",
    "            dummy = np.zeros((len(scaled_values),  self.X.shape[2]))\n",
    "            dummy[:, 3] = scaled_values  # 将预测值放入close列\n",
    "            return scaler.inverse_transform(dummy)[:, 3]\n",
    "        else:\n",
    "            raise ValueError(f\"No scaler found for code: {code}\")\n",
    "\n",
    "    \n",
    "\n",
    "class MultiScaleAttentionLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size = 64, num_layers_long = 3, num_layers_short = 2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm_long  = nn.LSTM(input_size, hidden_size, num_layers=num_layers_long, batch_first=True, dropout=0.2 if num_layers_long > 1 else 0)\n",
    "        self.lstm_short  = nn.LSTM(input_size, hidden_size, num_layers=num_layers_short, batch_first=True, dropout=0.2 if num_layers_short > 1 else 0)\n",
    "        self.attn  = nn.MultiheadAttention(hidden_size, num_heads=4, batch_first=True, )  # 4头注意力 \n",
    "        \n",
    "        self.regressor  = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 32),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    " \n",
    "    def forward(self, x1, seq_length_short=7):\n",
    "        out1, _ = self.lstm_long(x1) \n",
    "        out2, _ = self.lstm_short(x1[:, -seq_length_short:, :]) # lstm_out: [batch, seq_len, hidden]\n",
    "        lstm_out = torch.cat((out1,  out2), dim=1)\n",
    "        attn_out, _ = self.attn(lstm_out,  lstm_out, lstm_out, need_weights=False) \n",
    "        out = self.regressor(attn_out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a9e7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Current LR = 0.001\n",
      "Epoch 0 | Train Loss: 0.255130 | Test Loss: 0.233216\n",
      "low\n",
      "stock name: 阿尔茨海默概念, stock code: 886056, 今天收盘价：1287.4, 预测的后天收盘价: 966.09\n",
      "low\n",
      "stock name: AI PC, stock code: 886071, 今天收盘价：1783.487, 预测的后天收盘价: 1204.72\n"
     ]
    }
   ],
   "source": [
    "# 创建数据集 \n",
    "dataset = StockDataset(bk_data_ls, seq_length=16, forecast_gap=2)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_set, test_set = torch.utils.data.random_split( \n",
    "    dataset, [train_size, len(dataset) - train_size]\n",
    ")\n",
    "\n",
    "# 数据加载器 \n",
    "train_loader = DataLoader(train_set, batch_size=100000, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=100000)\n",
    "\n",
    "# 模型初始化\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 加载模型（需先实例化结构）\n",
    "model = MultiScaleAttentionLSTM(\n",
    "    input_size=7,  # 7个特征 \n",
    "    hidden_size=64,\n",
    "    num_layers_long = 3, \n",
    "    num_layers_short = 2\n",
    ").to(device)\n",
    "\n",
    "if os.path.exists('./model/model.pth'):\n",
    "    model.load_state_dict(torch.load('./model/model.pth')) \n",
    "\n",
    "# 训练参数 \n",
    "criterion = nn.MSELoss()\n",
    "scaler = amp.GradScaler(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),  lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( \n",
    "    optimizer, \n",
    "    mode='min',       # 监控验证损失\n",
    "    factor=0.5,       # 学习率衰减系数 \n",
    "    patience=5,       # 容忍5个epoch无改善\n",
    ")\n",
    "\n",
    "# ===== 4. 训练循环 =====\n",
    "for epoch in range(100):\n",
    "    model.train() \n",
    "    train_loss = 0 \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device),  y_batch.to(device) \n",
    "        \n",
    "        with amp.autocast(device_type=device): \n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "        train_loss += loss.item()\n",
    "        # 反向传播（自动处理精度）\n",
    "        scaler.scale(loss).backward()   # 缩放梯度\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)          # 更新参数 \n",
    "        scaler.update()                 # 调整缩放因子 \n",
    "        optimizer.zero_grad() \n",
    "    print(f\"Epoch {epoch+1}: Current LR = {scheduler.get_last_lr()[0]}\") \n",
    "    # 验证\n",
    "    model.eval() \n",
    "    test_loss = 0\n",
    "    with torch.no_grad(): \n",
    "        for X_test, y_test in test_loader:\n",
    "            X_test, y_test = X_test.to(device),  y_test.to(device) \n",
    "            preds = model(X_test)\n",
    "            test_loss += criterion(preds, y_test).item()\n",
    "    \n",
    "    scheduler.step(test_loss) \n",
    "    print(f'Epoch {epoch} | Train Loss: {train_loss/len(train_loader):.6f} | Test Loss: {test_loss/len(test_loader):.6f}')\n",
    "\n",
    "torch.save(model.state_dict(),  './model/model.pth') \n",
    "\n",
    "# ===== 5. 预测示例 =====\n",
    "model.eval() \n",
    "with torch.no_grad():\n",
    "    for name, code, data in bk_data_ls:\n",
    "        scaler = dataset.get_scaler(code)\n",
    "        max_index = len(data) - dataset.seq_length\n",
    "        seq_features = scaler.transform(data[[\"open\", \"high\", \"low\", \"close\", \"volume\", \"amount\"]].iloc[max_index:])\n",
    "        code_feature = code_scaler.transform(data[['code']].iloc[max_index:])\n",
    "        seq_features = np.insert(seq_features,  1, code_feature, axis=1)\n",
    "        X = torch.tensor(seq_features,  dtype=torch.float16).to(device)\n",
    "        X=X.unsqueeze(0)  # 添加批次维度\n",
    "\n",
    "        prediction = model(X)\n",
    "        scaled_pred = prediction.cpu().numpy() \n",
    "        \n",
    "        # 逆归一化收盘价 \n",
    "        dummy = np.zeros((1,  6))\n",
    "        dummy[:, 3] = scaled_pred  # 将预测值放入close列\n",
    "        real_pred = scaler.inverse_transform(dummy)[0,  3]\n",
    "        if real_pred > data.iloc[-1,  3]:\n",
    "            print(\"high\")\n",
    "        else:\n",
    "            print(\"low\")\n",
    "        print(f'stock name: {name}, stock code: {code}, 今天收盘价：{data.iloc[-1,  3]}, 预测的后天收盘价: {real_pred:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1a6d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734c8eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b84f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3ed238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
